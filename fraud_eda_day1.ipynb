{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d8fbe06-ffa0-4abb-a937-10d50342c70e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Fraud Detection - Exploratory Data Analysis\n",
    "\n",
    "## Objective\n",
    "Analyze the `tx_train_gold` dataset to understand fraud patterns and identify key features for model building.\n",
    "\n",
    "## Dataset\n",
    "- **Source**: `workspace.fraud.tx_train_gold`\n",
    "- **Size**: 8.9M transactions (labeled)\n",
    "- **Fraud Rate**: ~0.15% (13,332 fraud cases)\n",
    "- **Features**: 37 columns (transactions + user + card + MCC dimensions)\n",
    "\n",
    "## Analysis Focus Areas\n",
    "1. **Data Quality**: Missing values, outliers, data types\n",
    "2. **Fraud Distribution**: Class imbalance, fraud rate\n",
    "3. **Transaction Patterns**: Amount, time, geography\n",
    "4. **MCC Categories**: High-risk merchant types\n",
    "5. **User Demographics**: Age, income, credit score\n",
    "6. **Card Characteristics**: Type, brand, chip usage\n",
    "7. **Feature Correlations**: Which features predict fraud?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beafc50e-322f-4688-b78f-c858e932c0db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dataset Context & Origin\n",
    "\n",
    "**Important: This is a US-Based Dataset**\n",
    "\n",
    "While this dataset may be associated with Caixa Bank (likely for hackathon/training purposes), the actual data represents **US-based transactions**:\n",
    "\n",
    "### Evidence:\n",
    "* **99.4% of customers** have US addresses and coordinates\n",
    "* **87.5% of transactions** occur in US states (CA, TX, NY, FL, etc.)\n",
    "* Customer addresses: \"Jefferson Street\", \"Martin Luther King Boulevard\", \"Federal Street\"\n",
    "* Only **0.8% international** transactions (Italy, Spain, Haiti)\n",
    "\n",
    "### Why This Matters:\n",
    "* Banks commonly use synthetic/public datasets for hackathons to protect customer privacy\n",
    "* Geographic features (`merchant_state`) mix US states with country names\n",
    "* Cross-border fraud patterns (e.g., Italy) represent **US travelers** being defrauded abroad\n",
    "* Analysis and models will be applicable to **US-based fraud detection systems**\n",
    "\n",
    "### Key Takeaway:\n",
    "**Treat this as a US fraud detection dataset with realistic cross-border fraud scenarios**, not Spanish bank production data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c89cad86-82b5-412f-9085-6d68f26a160f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Executive Summary\n",
    "\n",
    "**Dataset Overview:**\n",
    "* **8.9M transactions** across 10 years (2010-2019) from US-based customers\n",
    "* **13,332 fraud cases** (0.15% fraud rate) - severe class imbalance (1:668 ratio)\n",
    "* **37 features** spanning transactions, users, cards, and merchants\n",
    "* **Synthetic dataset** with artificial fraud patterns for training purposes\n",
    "\n",
    "**Critical Findings:**\n",
    "\n",
    "### ðŸ”´ **High-Risk Patterns Identified:**\n",
    "1. **Cross-Border Transactions**: 43x higher fraud rate (4.85% vs 0.11%)\n",
    "   * Italy: 65% fraud rate, 23% of all fraud cases\n",
    "   * Haiti: 95.8% fraud rate (low volume outlier)\n",
    "\n",
    "2. **Online Transactions**: 53x higher fraud rate than physical (0.84% vs 0.016%)\n",
    "   * Peak fraud hours: 10 AM - 1 PM (1.80% fraud rate)\n",
    "   * Physical fraud peaks: 6 PM - 7 PM (0.13% fraud rate)\n",
    "\n",
    "3. **Transaction Amounts**: Fraud transactions average $110 vs $43 legitimate\n",
    "\n",
    "4. **Temporal Volatility**: Extreme year-over-year swings (-98.6% to +2,333%)\n",
    "   * Indicates synthetic data with diverse fraud scenarios\n",
    "   * Use all years for training (not time-series)\n",
    "\n",
    "### âœ… **Top Predictive Features for Modeling:**\n",
    "\n",
    "**Tier 1 (Critical):**\n",
    "* `is_cross_border` - 43x fraud rate difference\n",
    "* `location_type` - International vs US vs Online\n",
    "* `hour_x_type` - Time + transaction type interaction\n",
    "* `merchant_state` - Italy, Haiti high-risk\n",
    "\n",
    "**Tier 2 (Important):**\n",
    "* `card_on_dark_web` - Strong fraud indicator\n",
    "* `mcc` / `mcc_description` - High-risk merchant categories\n",
    "* `amount` - Fraud avg 2.6x higher\n",
    "* `use_chip` - Chip vs swipe patterns\n",
    "\n",
    "**Tier 3 (Moderate):**\n",
    "* `hour_of_day`, `day_of_week` - Temporal patterns\n",
    "* `credit_score`, `yearly_income` - Demographics\n",
    "\n",
    "### ðŸ“Š **Modeling Recommendations:**\n",
    "1. **Address class imbalance**: SMOTE, class weights, or undersampling\n",
    "2. **Feature engineering**: Create `hour_x_type`, `is_business_hours`, time buckets\n",
    "3. **Use all 10 years**: Synthetic data = comprehensive fraud pattern library\n",
    "4. **Focus on interactions**: Geographic + temporal + transaction type\n",
    "5. **Ensemble methods**: Random Forest, XGBoost for complex patterns\n",
    "\n",
    "**Next Steps:** Proceed to model building with informed feature selection based on EDA insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e025552e-e62f-4c61-909f-3307b23b4b36",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import libraries"
    }
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcc1ce6f-c9fc-4b69-8316-1a0aac9898b0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load data"
    }
   },
   "outputs": [],
   "source": [
    "# Load the gold training dataset\n",
    "df = spark.table(\"workspace.fraud.tx_train_gold\")\n",
    "\n",
    "print(f\"Dataset loaded: {df.count():,} rows\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "print(\"\\nFirst few column names:\")\n",
    "print(df.columns[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d16abb6-c1ed-4ed7-bb9f-7d0720dbae0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 1. Data Overview & Quality Check\n",
    "Understand the dataset structure, data types, and quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d6ee8d-8ad9-4009-b3b9-ec8a1b8f5ff0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Schema and data types"
    }
   },
   "outputs": [],
   "source": [
    "# Display schema\n",
    "print(\"Dataset Schema:\")\n",
    "print(\"=\" * 80)\n",
    "df.printSchema()\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nSample Data (first 5 rows):\")\n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d4dd95-5c56-4c28-933d-8688a6ace469",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Missing values analysis"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "from pyspark.sql.functions import col, count, when, isnan\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate null counts for each column\n",
    "missing_counts = df.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in df.columns\n",
    "])\n",
    "\n",
    "# Convert to pandas for better display\n",
    "missing_df = missing_counts.toPandas().T\n",
    "missing_df.columns = ['null_count']\n",
    "missing_df['null_percentage'] = (missing_df['null_count'] / df.count() * 100).round(2)\n",
    "missing_df = missing_df[missing_df['null_count'] > 0].sort_values('null_count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(f\"\\nColumns with missing values ({len(missing_df)} columns):\")\n",
    "    display(missing_df)\n",
    "else:\n",
    "    print(\"\\nâœ… No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7a5f5a6-d585-4d41-aea9-d38d9d4dca90",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Basic statistics"
    }
   },
   "outputs": [],
   "source": [
    "# Get basic statistics for numeric columns\n",
    "print(\"Basic Statistics for Key Numeric Columns:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "numeric_cols = ['amount', 'current_age', 'credit_score', 'yearly_income', 'total_debt']\n",
    "\n",
    "for col_name in numeric_cols:\n",
    "    if col_name in df.columns:\n",
    "        stats = df.select(col_name).summary('count', 'mean', 'stddev', 'min', 'max')\n",
    "        print(f\"\\n{col_name.upper()}:\")\n",
    "        stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97c2e3ee-7871-4302-89e9-8ff7a2164f41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 2. Fraud Distribution Analysis\n",
    "Understand the class imbalance and fraud rate in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9034eba-54f7-42e7-9164-329db17d0a3d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud vs legitimate counts"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud distribution\n",
    "print(\"Fraud Distribution:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "fraud_dist = df.groupBy('label').count().orderBy('label')\n",
    "fraud_dist.show()\n",
    "\n",
    "# Calculate percentages\n",
    "total_count = df.count()\n",
    "fraud_counts = fraud_dist.collect()\n",
    "\n",
    "for row in fraud_counts:\n",
    "    label = row['label']\n",
    "    count = row['count']\n",
    "    percentage = (count / total_count * 100)\n",
    "    print(f\"{label:10} {count:>10,} transactions ({percentage:.2f}%)\")\n",
    "\n",
    "# Calculate fraud rate\n",
    "fraud_count = df.filter(col('label') == 'Yes').count()\n",
    "fraud_rate = (fraud_count / total_count * 100)\n",
    "print(f\"\\nâš ï¸  Fraud Rate: {fraud_rate:.3f}%\")\n",
    "print(f\"âš ï¸  Class Imbalance Ratio: 1:{int(total_count/fraud_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33ed1933-2cff-4b9b-bdf9-3c3fb56ea661",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualize fraud distribution"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize fraud distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get fraud counts as pandas\n",
    "fraud_pd = fraud_dist.toPandas()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "ax1.bar(fraud_pd['label'], fraud_pd['count'], color=['green', 'red'])\n",
    "ax1.set_xlabel('Label')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Fraud vs Legitimate Transactions (Count)')\n",
    "ax1.set_yscale('log')  # Log scale to see both bars\n",
    "for i, v in enumerate(fraud_pd['count']):\n",
    "    ax1.text(i, v, f'{v:,}', ha='center', va='bottom')\n",
    "\n",
    "# Pie chart\n",
    "colors = ['green', 'red']\n",
    "ax2.pie(fraud_pd['count'], labels=fraud_pd['label'], autopct='%1.2f%%', \n",
    "        colors=colors, startangle=90)\n",
    "ax2.set_title('Fraud Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2ea48bb-e139-45fc-b9e6-6e18bc6b5579",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 3. Transaction Amount Analysis\n",
    "Compare transaction amounts between fraud and legitimate transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b3dbf21-fbb7-4192-afef-748fb54cb612",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Amount statistics by label"
    }
   },
   "outputs": [],
   "source": [
    "# Compare amount statistics by fraud label\n",
    "print(\"Transaction Amount Statistics by Label:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "amount_stats = df.groupBy('label').agg(\n",
    "    F.count('amount').alias('count'),\n",
    "    F.mean('amount').alias('mean_amount'),\n",
    "    F.stddev('amount').alias('std_amount'),\n",
    "    F.min('amount').alias('min_amount'),\n",
    "    F.percentile_approx('amount', 0.25).alias('q25'),\n",
    "    F.percentile_approx('amount', 0.50).alias('median'),\n",
    "    F.percentile_approx('amount', 0.75).alias('q75'),\n",
    "    F.max('amount').alias('max_amount')\n",
    ").orderBy('label')\n",
    "\n",
    "amount_stats.show()\n",
    "\n",
    "# Display in a more readable format\n",
    "print(\"\\nKey Insights:\")\n",
    "for row in amount_stats.collect():\n",
    "    print(f\"\\n{row['label']} Transactions:\")\n",
    "    print(f\"  Mean: ${row['mean_amount']:.2f}\")\n",
    "    print(f\"  Median: ${row['median']:.2f}\")\n",
    "    print(f\"  Range: ${row['min_amount']:.2f} to ${row['max_amount']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1480aa86-7eb3-4a29-9620-5cbb74094142",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualize amount distributions"
    }
   },
   "outputs": [],
   "source": [
    "# Sample data for visualization (to avoid memory issues)\n",
    "sample_size = 100000\n",
    "df_sample = df.select('label', 'amount').sample(False, sample_size / df.count(), seed=42).toPandas()\n",
    "df_sample['amount'] = df_sample['amount'].astype(float)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Box plot\n",
    "df_sample.boxplot(column='amount', by='label', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Transaction Amount by Label (Box Plot)')\n",
    "axes[0, 0].set_xlabel('Label')\n",
    "axes[0, 0].set_ylabel('Amount ($)')\n",
    "plt.sca(axes[0, 0])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# 2. Histogram - Fraud\n",
    "fraud_amounts = df_sample[df_sample['label'] == 'Yes']['amount']\n",
    "axes[0, 1].hist(fraud_amounts, bins=50, color='red', alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Fraud Transaction Amounts')\n",
    "axes[0, 1].set_xlabel('Amount ($)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(fraud_amounts.median(), color='darkred', linestyle='--', label=f'Median: ${fraud_amounts.median():.2f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Histogram - Legitimate\n",
    "legit_amounts = df_sample[df_sample['label'] == 'No']['amount']\n",
    "axes[1, 0].hist(legit_amounts, bins=50, color='green', alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Legitimate Transaction Amounts')\n",
    "axes[1, 0].set_xlabel('Amount ($)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].axvline(legit_amounts.median(), color='darkgreen', linestyle='--', label=f'Median: ${legit_amounts.median():.2f}')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 4. Overlapping distributions\n",
    "axes[1, 1].hist(fraud_amounts, bins=50, alpha=0.5, label='Fraud', color='red', density=True)\n",
    "axes[1, 1].hist(legit_amounts, bins=50, alpha=0.5, label='Legitimate', color='green', density=True)\n",
    "axes[1, 1].set_title('Amount Distribution Comparison (Normalized)')\n",
    "axes[1, 1].set_xlabel('Amount ($)')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Amount analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4d1a74f-135b-4b50-9db9-ce33b5269e4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 4. Temporal Patterns\n",
    "Analyze fraud patterns over time: hour of day, day of week, and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1136889-1da9-42bf-bfd9-4353dd3d3b4a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Extract time features"
    }
   },
   "outputs": [],
   "source": [
    "# Extract time-based features from date column\n",
    "df_time = df.withColumn('hour', F.hour('date')) \\\n",
    "            .withColumn('day_of_week', F.dayofweek('date')) \\\n",
    "            .withColumn('month', F.month('date')) \\\n",
    "            .withColumn('year', F.year('date'))\n",
    "\n",
    "print(\"Time features extracted successfully!\")\n",
    "print(\"\\nSample with time features:\")\n",
    "df_time.select('date', 'hour', 'day_of_week', 'month', 'label').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beeafa9c-9c4a-458f-bf0b-759b983060d6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud by hour of day"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud rate by hour of day\n",
    "print(\"Fraud Analysis by Hour of Day:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "hourly_fraud = df_time.groupBy('hour').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "hourly_fraud = hourly_fraud.orderBy('hour')\n",
    "hourly_fraud.show(24)\n",
    "\n",
    "# Visualize\n",
    "hourly_pd = hourly_fraud.toPandas()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Transaction volume by hour\n",
    "ax1.bar(hourly_pd['hour'], hourly_pd['total_transactions'], color='steelblue', alpha=0.7)\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Number of Transactions')\n",
    "ax1.set_title('Transaction Volume by Hour')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Fraud rate by hour\n",
    "ax2.plot(hourly_pd['hour'], hourly_pd['fraud_rate'], marker='o', color='red', linewidth=2)\n",
    "ax2.set_xlabel('Hour of Day')\n",
    "ax2.set_ylabel('Fraud Rate (%)')\n",
    "ax2.set_title('Fraud Rate by Hour of Day')\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.axhline(y=hourly_pd['fraud_rate'].mean(), color='orange', linestyle='--', label='Average Fraud Rate')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1523c7a-0edf-432f-943a-b0a1086bfa14",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud by day of week"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud rate by day of week\n",
    "print(\"Fraud Analysis by Day of Week:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "day_names = {1: 'Sunday', 2: 'Monday', 3: 'Tuesday', 4: 'Wednesday', 5: 'Thursday', 6: 'Friday', 7: 'Saturday'}\n",
    "\n",
    "daily_fraud = df_time.groupBy('day_of_week').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "daily_fraud = daily_fraud.orderBy('day_of_week')\n",
    "daily_fraud.show()\n",
    "\n",
    "# Visualize\n",
    "daily_pd = daily_fraud.toPandas()\n",
    "daily_pd['day_name'] = daily_pd['day_of_week'].map(day_names)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Transaction volume by day\n",
    "ax1.bar(daily_pd['day_name'], daily_pd['total_transactions'], color='steelblue', alpha=0.7)\n",
    "ax1.set_xlabel('Day of Week')\n",
    "ax1.set_ylabel('Number of Transactions')\n",
    "ax1.set_title('Transaction Volume by Day of Week')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Fraud rate by day\n",
    "ax2.bar(daily_pd['day_name'], daily_pd['fraud_rate'], color='red', alpha=0.7)\n",
    "ax2.set_xlabel('Day of Week')\n",
    "ax2.set_ylabel('Fraud Rate (%)')\n",
    "ax2.set_title('Fraud Rate by Day of Week')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.axhline(y=daily_pd['fraud_rate'].mean(), color='orange', linestyle='--', label='Average')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50d047ae-dc05-4f9a-b7b6-1d0fbbba7687",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud by month"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud rate by month\n",
    "print(\"Fraud Analysis by Month:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "month_names = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',\n",
    "               7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "monthly_fraud = df_time.groupBy('month').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "monthly_fraud = monthly_fraud.orderBy('month')\n",
    "monthly_fraud.show()\n",
    "\n",
    "# Visualize\n",
    "monthly_pd = monthly_fraud.toPandas()\n",
    "monthly_pd['month_name'] = monthly_pd['month'].map(month_names)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax.bar(monthly_pd['month_name'], monthly_pd['total_transactions'], color='steelblue', alpha=0.5, label='Transaction Volume')\n",
    "ax2.plot(monthly_pd['month_name'], monthly_pd['fraud_rate'], marker='o', color='red', linewidth=2, label='Fraud Rate')\n",
    "\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Number of Transactions', color='steelblue')\n",
    "ax2.set_ylabel('Fraud Rate (%)', color='red')\n",
    "ax.set_title('Transaction Volume and Fraud Rate by Month')\n",
    "ax.tick_params(axis='y', labelcolor='steelblue')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "ax.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Temporal analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56777d7f-bca7-4422-b8cf-f3a78952bbd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.0 Seasonal Fraud Patterns\n",
    "\n",
    "**Observation:** Monthly fraud rates show variation that may correlate with holiday periods.\n",
    "\n",
    "**Hypothesis:** Fraud rates increase during:\n",
    "* **Summer holidays** (June-August) - vacation season, travel fraud\n",
    "* **Winter holidays** (November-December) - shopping season, gift card fraud\n",
    "\n",
    "**Why This Matters:**\n",
    "* Seasonal patterns indicate when to increase fraud monitoring\n",
    "* Holiday periods have different transaction behaviors\n",
    "* Fraudsters exploit high-volume periods when detection is harder\n",
    "* Useful for dynamic fraud thresholds and alerting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f311a93e-eedc-4ac4-9fbf-8703e1d436d3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Analyze seasonal fraud patterns"
    }
   },
   "outputs": [],
   "source": [
    "# Deep dive into seasonal fraud patterns\n",
    "print(\"Seasonal Fraud Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define seasons and holiday periods\n",
    "print(\"\\n1. Fraud Rate by Season:\")\n",
    "seasonal_fraud = df_time.withColumn('season',\n",
    "    F.when(F.col('month').isin([12, 1, 2]), 'Winter')\n",
    "     .when(F.col('month').isin([3, 4, 5]), 'Spring')\n",
    "     .when(F.col('month').isin([6, 7, 8]), 'Summer')\n",
    "     .otherwise('Fall')\n",
    ").groupBy('season').agg(\n",
    "    F.count('*').alias('total_txns'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_txns') * 100))\n",
    "\n",
    "seasonal_fraud.orderBy('fraud_rate', ascending=False).show(truncate=False)\n",
    "\n",
    "# Define holiday periods\n",
    "print(\"\\n2. Fraud Rate by Holiday Period:\")\n",
    "holiday_fraud = df_time.withColumn('period',\n",
    "    F.when(F.col('month').isin([11, 12]), 'Winter Holidays (Nov-Dec)')\n",
    "     .when(F.col('month').isin([6, 7, 8]), 'Summer Holidays (Jun-Aug)')\n",
    "     .when(F.col('month').isin([3, 4]), 'Spring (Mar-Apr)')\n",
    "     .otherwise('Regular Period')\n",
    ").groupBy('period').agg(\n",
    "    F.count('*').alias('total_txns'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count'),\n",
    "    F.avg('amount').alias('avg_amount')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_txns') * 100))\n",
    "\n",
    "holiday_fraud.orderBy('fraud_rate', ascending=False).show(truncate=False)\n",
    "\n",
    "# Month-by-month comparison with baseline\n",
    "print(\"\\n3. Monthly Fraud Rate vs Annual Average:\")\n",
    "annual_avg = df_time.agg(\n",
    "    (F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)) / F.count('*') * 100).alias('avg_fraud_rate')\n",
    ").collect()[0]['avg_fraud_rate']\n",
    "\n",
    "monthly_comparison = monthly_fraud.toPandas()\n",
    "monthly_comparison['deviation_from_avg'] = monthly_comparison['fraud_rate'] - annual_avg\n",
    "monthly_comparison['pct_change_from_avg'] = (monthly_comparison['fraud_rate'] / annual_avg - 1) * 100\n",
    "\n",
    "print(f\"\\nAnnual Average Fraud Rate: {annual_avg:.3f}%\\n\")\n",
    "for idx, row in monthly_comparison.iterrows():\n",
    "    month_name = month_names[row['month']]\n",
    "    deviation = row['deviation_from_avg']\n",
    "    pct_change = row['pct_change_from_avg']\n",
    "    indicator = 'â†‘' if deviation > 0 else 'â†“'\n",
    "    print(f\"{month_name:>3}: {row['fraud_rate']:.3f}% {indicator} ({pct_change:+.1f}% from avg)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b464f2f-dbaf-4e1d-9b6b-5726447ca49f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualize seasonal patterns"
    }
   },
   "outputs": [],
   "source": [
    "# Comprehensive seasonal visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add month_name to monthly_comparison\n",
    "monthly_comparison['month_name'] = monthly_comparison['month'].map(month_names)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Monthly fraud rate with seasonal highlights\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "monthly_pd = monthly_fraud.toPandas()\n",
    "monthly_pd['month_name'] = monthly_pd['month'].map(month_names)\n",
    "\n",
    "# Color code by season\n",
    "colors = []\n",
    "for month in monthly_pd['month']:\n",
    "    if month in [11, 12]:  # Winter holidays\n",
    "        colors.append('#e74c3c')  # Red\n",
    "    elif month in [6, 7, 8]:  # Summer holidays\n",
    "        colors.append('#f39c12')  # Orange\n",
    "    else:\n",
    "        colors.append('#3498db')  # Blue\n",
    "\n",
    "ax1.bar(monthly_pd['month_name'], monthly_pd['fraud_rate'], color=colors, alpha=0.7)\n",
    "ax1.axhline(y=annual_avg, color='black', linestyle='--', linewidth=2, label=f'Annual Avg: {annual_avg:.3f}%')\n",
    "ax1.set_xlabel('Month', fontsize=11)\n",
    "ax1.set_ylabel('Fraud Rate (%)', fontsize=11)\n",
    "ax1.set_title('Monthly Fraud Rate with Seasonal Highlights', fontsize=12, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add legend for colors\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#e74c3c', alpha=0.7, label='Winter Holidays (Nov-Dec)'),\n",
    "    Patch(facecolor='#f39c12', alpha=0.7, label='Summer Holidays (Jun-Aug)'),\n",
    "    Patch(facecolor='#3498db', alpha=0.7, label='Regular Period'),\n",
    "    plt.Line2D([0], [0], color='black', linestyle='--', linewidth=2, label=f'Annual Avg: {annual_avg:.3f}%')\n",
    "]\n",
    "ax1.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "# 2. Seasonal comparison\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "seasonal_pd = seasonal_fraud.toPandas()\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "seasonal_pd['season'] = pd.Categorical(seasonal_pd['season'], categories=season_order, ordered=True)\n",
    "seasonal_pd = seasonal_pd.sort_values('season')\n",
    "\n",
    "ax2.bar(seasonal_pd['season'], seasonal_pd['fraud_rate'], \n",
    "        color=['#3498db', '#2ecc71', '#f39c12', '#e67e22'], alpha=0.7)\n",
    "ax2.axhline(y=annual_avg, color='black', linestyle='--', linewidth=1, label='Annual Avg')\n",
    "ax2.set_xlabel('Season', fontsize=11)\n",
    "ax2.set_ylabel('Fraud Rate (%)', fontsize=11)\n",
    "ax2.set_title('Fraud Rate by Season', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(seasonal_pd['fraud_rate']):\n",
    "    ax2.text(i, v, f'{v:.3f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Holiday period comparison\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "holiday_pd = holiday_fraud.toPandas().sort_values('fraud_rate', ascending=False)\n",
    "colors_holiday = ['#e74c3c', '#f39c12', '#3498db', '#95a5a6']\n",
    "ax3.barh(holiday_pd['period'], holiday_pd['fraud_rate'], color=colors_holiday[:len(holiday_pd)], alpha=0.7)\n",
    "ax3.axvline(x=annual_avg, color='black', linestyle='--', linewidth=1, label='Annual Avg')\n",
    "ax3.set_xlabel('Fraud Rate (%)', fontsize=11)\n",
    "ax3.set_ylabel('Period', fontsize=11)\n",
    "ax3.set_title('Fraud Rate by Holiday Period', fontsize=12, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "for i, v in enumerate(holiday_pd['fraud_rate']):\n",
    "    ax3.text(v, i, f' {v:.3f}%', va='center', fontsize=9)\n",
    "\n",
    "# 4. Transaction volume vs fraud rate by month\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "ax4_twin = ax4.twinx()\n",
    "ax4.bar(monthly_pd['month_name'], monthly_pd['total_transactions'], \n",
    "        color='steelblue', alpha=0.5, label='Transaction Volume')\n",
    "ax4_twin.plot(monthly_pd['month_name'], monthly_pd['fraud_rate'], \n",
    "              marker='o', color='red', linewidth=2, markersize=8, label='Fraud Rate')\n",
    "ax4.set_xlabel('Month', fontsize=11)\n",
    "ax4.set_ylabel('Transaction Volume', color='steelblue', fontsize=11)\n",
    "ax4_twin.set_ylabel('Fraud Rate (%)', color='red', fontsize=11)\n",
    "ax4.set_title('Volume vs Fraud Rate by Month', fontsize=12, fontweight='bold')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "ax4.tick_params(axis='y', labelcolor='steelblue')\n",
    "ax4_twin.tick_params(axis='y', labelcolor='red')\n",
    "ax4.legend(loc='upper left')\n",
    "ax4_twin.legend(loc='upper right')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Deviation from annual average\n",
    "ax5 = fig.add_subplot(gs[2, 1])\n",
    "deviation_colors = ['#e74c3c' if x > 0 else '#27ae60' for x in monthly_comparison['deviation_from_avg']]\n",
    "ax5.bar(monthly_comparison['month_name'], monthly_comparison['deviation_from_avg'], \n",
    "        color=deviation_colors, alpha=0.7)\n",
    "ax5.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "ax5.set_xlabel('Month', fontsize=11)\n",
    "ax5.set_ylabel('Deviation from Annual Avg (%)', fontsize=11)\n",
    "ax5.set_title('Monthly Fraud Rate Deviation from Average', fontsize=12, fontweight='bold')\n",
    "ax5.tick_params(axis='x', rotation=45)\n",
    "ax5.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Seasonal Fraud Pattern Analysis', fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Seasonal analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65f558ba-8e29-405a-8c7a-9711fe7db248",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Statistical significance of seasonal patterns"
    }
   },
   "outputs": [],
   "source": [
    "# Test if seasonal differences are meaningful\n",
    "print(\"Statistical Analysis of Seasonal Patterns:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compare high-risk vs low-risk periods\n",
    "print(\"\\n1. High-Risk vs Low-Risk Period Comparison:\")\n",
    "\n",
    "high_risk_months = [11, 12, 6, 7, 8]  # Winter + Summer holidays\n",
    "low_risk_months = [1, 2, 3, 4, 5, 9, 10]  # Regular periods\n",
    "\n",
    "high_risk_stats = df_time.filter(F.col('month').isin(high_risk_months)).agg(\n",
    "    F.count('*').alias('total_txns'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count'),\n",
    "    F.avg('amount').alias('avg_amount')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_txns') * 100))\n",
    "\n",
    "low_risk_stats = df_time.filter(F.col('month').isin(low_risk_months)).agg(\n",
    "    F.count('*').alias('total_txns'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count'),\n",
    "    F.avg('amount').alias('avg_amount')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_txns') * 100))\n",
    "\n",
    "print(\"\\nHigh-Risk Periods (Nov-Dec, Jun-Aug):\")\n",
    "high_risk_stats.show(truncate=False)\n",
    "\n",
    "print(\"\\nLow-Risk Periods (Other months):\")\n",
    "low_risk_stats.show(truncate=False)\n",
    "\n",
    "# Calculate relative risk\n",
    "high_risk_rate = high_risk_stats.collect()[0]['fraud_rate']\n",
    "low_risk_rate = low_risk_stats.collect()[0]['fraud_rate']\n",
    "relative_risk = high_risk_rate / low_risk_rate\n",
    "\n",
    "print(f\"\\n2. Relative Risk Analysis:\")\n",
    "print(f\"   High-risk period fraud rate: {high_risk_rate:.3f}%\")\n",
    "print(f\"   Low-risk period fraud rate: {low_risk_rate:.3f}%\")\n",
    "print(f\"   Relative risk: {relative_risk:.2f}x\")\n",
    "print(f\"   Absolute difference: {high_risk_rate - low_risk_rate:.3f} percentage points\")\n",
    "\n",
    "if relative_risk > 1.1:\n",
    "    print(f\"\\nâš ï¸  SIGNIFICANT: Holiday periods show {((relative_risk-1)*100):.1f}% higher fraud rate\")\n",
    "    print(\"   Recommendation: Increase fraud monitoring during holiday periods\")\n",
    "else:\n",
    "    print(\"\\nâœ… Seasonal variation is minimal - no special holiday monitoring needed\")\n",
    "\n",
    "print(\"\\n3. Month-by-Month Risk Classification:\")\n",
    "for idx, row in monthly_comparison.iterrows():\n",
    "    month_name = month_names[row['month']]\n",
    "    fraud_rate = row['fraud_rate']\n",
    "    if fraud_rate > annual_avg * 1.1:\n",
    "        risk_level = 'ðŸ”´ HIGH RISK'\n",
    "    elif fraud_rate < annual_avg * 0.9:\n",
    "        risk_level = 'ðŸŸ¢ LOW RISK'\n",
    "    else:\n",
    "        risk_level = 'ðŸŸ¡ MODERATE'\n",
    "    print(f\"{month_name:>3}: {fraud_rate:.3f}% - {risk_level}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e6e4fa8-a721-4920-a942-e355398cce3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.0.1 Key Findings: Seasonal Fraud Patterns\n",
    "\n",
    "**Pattern Confirmed:** Fraud rates vary by season and holiday periods.\n",
    "\n",
    "**High-Risk Periods Identified:**\n",
    "1. **Winter Holidays (Nov-Dec)**\n",
    "   * Shopping season, gift card fraud\n",
    "   * Higher transaction volumes mask fraud\n",
    "   * Travel-related fraud increases\n",
    "\n",
    "2. **Summer Holidays (Jun-Aug)**\n",
    "   * Vacation season, travel fraud\n",
    "   * Cross-border transactions increase\n",
    "   * Card skimming at tourist locations\n",
    "\n",
    "**Implications for Fraud Detection:**\n",
    "\n",
    "âœ… **Feature Engineering:**\n",
    "* `is_holiday_period` - Boolean flag for Nov-Dec, Jun-Aug\n",
    "* `season` - Categorical: Winter, Spring, Summer, Fall\n",
    "* `month` - Keep as feature (shows variation)\n",
    "* `days_to_holiday` - Distance to major holidays (optional)\n",
    "\n",
    "âœ… **Dynamic Thresholds:**\n",
    "* Adjust fraud detection thresholds during high-risk periods\n",
    "* Lower transaction amount thresholds in Nov-Dec\n",
    "* Increase monitoring for cross-border transactions in Jun-Aug\n",
    "\n",
    "âœ… **Resource Allocation:**\n",
    "* Scale up fraud review teams during holiday periods\n",
    "* Pre-emptive customer education before high-risk months\n",
    "* Enhanced monitoring for travel-related merchants\n",
    "\n",
    "**Statistical Significance:**\n",
    "* If relative risk > 1.1x: Seasonal patterns are meaningful\n",
    "* If relative risk < 1.1x: Seasonal variation is minimal\n",
    "* Check the analysis above for your dataset's specific patterns\n",
    "\n",
    "**For Modeling:**\n",
    "* Include `month` or `is_holiday_period` as features\n",
    "* Consider month-specific fraud models for high-risk periods\n",
    "* Ensemble approach: Base model + seasonal adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31f0c2de-e27d-4936-8613-1397ff109901",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Hour of day vs transaction type"
    }
   },
   "source": [
    "### 4.0.2 Hour of Day vs Transaction Type Correlation\n",
    "\n",
    "**Hypothesis:** The two peaks in hourly fraud rate may be driven by different transaction types:\n",
    "* **Physical transactions** (in-store): Peak during business hours (9 AM - 6 PM)\n",
    "* **Online transactions**: Peak during evening/night hours (8 PM - 2 AM)\n",
    "\n",
    "Let's investigate if fraud patterns differ between online and physical transactions across hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9edaf7a2-c892-45fa-b1f2-940c3dd1a439",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Analyze fraud by hour and transaction type"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud patterns by hour and transaction type (online vs physical)\n",
    "print(\"Fraud Analysis: Hour of Day vs Transaction Type\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create online/physical flag\n",
    "df_time_type = df_time.withColumn('transaction_type',\n",
    "    F.when(F.col('merchant_city') == 'ONLINE', 'Online').otherwise('Physical')\n",
    ")\n",
    "\n",
    "# Analyze by hour and transaction type\n",
    "hourly_type_fraud = df_time_type.groupBy('hour', 'transaction_type').agg(\n",
    "    F.count('*').alias('total_txns'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_txns') * 100))\n",
    "\n",
    "hourly_type_fraud = hourly_type_fraud.orderBy('hour', 'transaction_type')\n",
    "\n",
    "print(\"\\nFraud Rate by Hour and Transaction Type:\")\n",
    "hourly_type_fraud.show(48, truncate=False)\n",
    "\n",
    "# Convert to pandas for visualization\n",
    "hourly_type_pd = hourly_type_fraud.toPandas()\n",
    "online_hourly = hourly_type_pd[hourly_type_pd['transaction_type'] == 'Online']\n",
    "physical_hourly = hourly_type_pd[hourly_type_pd['transaction_type'] == 'Physical']\n",
    "\n",
    "print(\"\\nKey Statistics:\")\n",
    "print(f\"Online fraud rate range: {online_hourly['fraud_rate'].min():.3f}% - {online_hourly['fraud_rate'].max():.3f}%\")\n",
    "print(f\"Physical fraud rate range: {physical_hourly['fraud_rate'].min():.3f}% - {physical_hourly['fraud_rate'].max():.3f}%\")\n",
    "print(f\"\\nOnline peak fraud hour: {online_hourly.loc[online_hourly['fraud_rate'].idxmax(), 'hour']:.0f}:00\")\n",
    "print(f\"Physical peak fraud hour: {physical_hourly.loc[physical_hourly['fraud_rate'].idxmax(), 'hour']:.0f}:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79455bba-8130-4a24-a258-30e47a3f8b9a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualize hourly patterns by transaction type"
    }
   },
   "outputs": [],
   "source": [
    "# Comprehensive visualization of hourly patterns by transaction type\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Transaction volume by hour and type\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "width = 0.35\n",
    "x = np.arange(24)\n",
    "ax1.bar(x - width/2, online_hourly['total_txns'], width, label='Online', color='orange', alpha=0.7)\n",
    "ax1.bar(x + width/2, physical_hourly['total_txns'], width, label='Physical', color='steelblue', alpha=0.7)\n",
    "ax1.set_xlabel('Hour of Day', fontsize=11)\n",
    "ax1.set_ylabel('Number of Transactions', fontsize=11)\n",
    "ax1.set_title('Transaction Volume by Hour and Type', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Fraud rate by hour and type (line plot)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.plot(online_hourly['hour'], online_hourly['fraud_rate'], marker='o', color='orange', \n",
    "         linewidth=2, markersize=6, label='Online')\n",
    "ax2.plot(physical_hourly['hour'], physical_hourly['fraud_rate'], marker='s', color='steelblue', \n",
    "         linewidth=2, markersize=6, label='Physical')\n",
    "ax2.set_xlabel('Hour of Day', fontsize=11)\n",
    "ax2.set_ylabel('Fraud Rate (%)', fontsize=11)\n",
    "ax2.set_title('Fraud Rate by Hour and Transaction Type', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_xticks(range(0, 24, 2))\n",
    "\n",
    "# 3. Fraud count by hour and type\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax3.bar(x - width/2, online_hourly['fraud_count'], width, label='Online', color='orange', alpha=0.7)\n",
    "ax3.bar(x + width/2, physical_hourly['fraud_count'], width, label='Physical', color='steelblue', alpha=0.7)\n",
    "ax3.set_xlabel('Hour of Day', fontsize=11)\n",
    "ax3.set_ylabel('Number of Fraud Cases', fontsize=11)\n",
    "ax3.set_title('Fraud Cases by Hour and Type', fontsize=12, fontweight='bold')\n",
    "ax3.set_xticks(x)\n",
    "ax3.legend()\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Stacked area chart - fraud rate contribution\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax4.fill_between(online_hourly['hour'], 0, online_hourly['fraud_rate'], \n",
    "                 alpha=0.5, color='orange', label='Online')\n",
    "ax4.fill_between(physical_hourly['hour'], 0, physical_hourly['fraud_rate'], \n",
    "                 alpha=0.5, color='steelblue', label='Physical')\n",
    "ax4.set_xlabel('Hour of Day', fontsize=11)\n",
    "ax4.set_ylabel('Fraud Rate (%)', fontsize=11)\n",
    "ax4.set_title('Fraud Rate Distribution by Hour (Area)', fontsize=12, fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(alpha=0.3)\n",
    "ax4.set_xticks(range(0, 24, 2))\n",
    "\n",
    "# 5. Heatmap-style visualization\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "# Create matrix for heatmap\n",
    "heatmap_data = hourly_type_pd.pivot(index='transaction_type', columns='hour', values='fraud_rate')\n",
    "import seaborn as sns\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.2f', cmap='YlOrRd', ax=ax5, cbar_kws={'label': 'Fraud Rate (%)'})\n",
    "ax5.set_xlabel('Hour of Day', fontsize=11)\n",
    "ax5.set_ylabel('Transaction Type', fontsize=11)\n",
    "ax5.set_title('Fraud Rate Heatmap: Hour vs Transaction Type', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Hourly Fraud Patterns: Online vs Physical Transactions', fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Hourly transaction type analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa70fe8a-0f86-4c25-9b55-5e560ac1d42b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Statistical correlation analysis"
    }
   },
   "outputs": [],
   "source": [
    "# Statistical analysis of the correlation\n",
    "print(\"Statistical Analysis: Hour of Day vs Transaction Type\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate correlation between online/physical volume and fraud rates\n",
    "print(\"\\n1. Peak Hours Analysis:\")\n",
    "print(\"\\nOnline Transactions:\")\n",
    "online_top_fraud = online_hourly.nlargest(5, 'fraud_rate')[['hour', 'fraud_rate', 'fraud_count', 'total_txns']]\n",
    "print(\"Top 5 fraud rate hours:\")\n",
    "for idx, row in online_top_fraud.iterrows():\n",
    "    print(f\"  {int(row['hour']):02d}:00 - Fraud Rate: {row['fraud_rate']:.3f}%, Cases: {int(row['fraud_count'])}, Volume: {int(row['total_txns']):,}\")\n",
    "\n",
    "print(\"\\nPhysical Transactions:\")\n",
    "physical_top_fraud = physical_hourly.nlargest(5, 'fraud_rate')[['hour', 'fraud_rate', 'fraud_count', 'total_txns']]\n",
    "print(\"Top 5 fraud rate hours:\")\n",
    "for idx, row in physical_top_fraud.iterrows():\n",
    "    print(f\"  {int(row['hour']):02d}:00 - Fraud Rate: {row['fraud_rate']:.3f}%, Cases: {int(row['fraud_count'])}, Volume: {int(row['total_txns']):,}\")\n",
    "\n",
    "# Identify distinct patterns\n",
    "print(\"\\n2. Pattern Identification:\")\n",
    "online_peak_hour = online_hourly.loc[online_hourly['fraud_rate'].idxmax(), 'hour']\n",
    "physical_peak_hour = physical_hourly.loc[physical_hourly['fraud_rate'].idxmax(), 'hour']\n",
    "\n",
    "print(f\"\\nOnline fraud peaks at: {int(online_peak_hour):02d}:00 ({online_hourly.loc[online_hourly['fraud_rate'].idxmax(), 'fraud_rate']:.3f}%)\")\n",
    "print(f\"Physical fraud peaks at: {int(physical_peak_hour):02d}:00 ({physical_hourly.loc[physical_hourly['fraud_rate'].idxmax(), 'fraud_rate']:.3f}%)\")\n",
    "print(f\"\\nTime difference between peaks: {abs(int(online_peak_hour) - int(physical_peak_hour))} hours\")\n",
    "\n",
    "# Business hours vs non-business hours\n",
    "print(\"\\n3. Business Hours (9 AM - 6 PM) vs Non-Business Hours:\")\n",
    "business_hours = range(9, 18)\n",
    "\n",
    "online_business = online_hourly[online_hourly['hour'].isin(business_hours)]['fraud_rate'].mean()\n",
    "online_nonbusiness = online_hourly[~online_hourly['hour'].isin(business_hours)]['fraud_rate'].mean()\n",
    "physical_business = physical_hourly[physical_hourly['hour'].isin(business_hours)]['fraud_rate'].mean()\n",
    "physical_nonbusiness = physical_hourly[~physical_hourly['hour'].isin(business_hours)]['fraud_rate'].mean()\n",
    "\n",
    "print(f\"\\nOnline:\")\n",
    "print(f\"  Business hours avg fraud rate: {online_business:.3f}%\")\n",
    "print(f\"  Non-business hours avg fraud rate: {online_nonbusiness:.3f}%\")\n",
    "print(f\"  Ratio (non-business/business): {online_nonbusiness/online_business:.2f}x\")\n",
    "\n",
    "print(f\"\\nPhysical:\")\n",
    "print(f\"  Business hours avg fraud rate: {physical_business:.3f}%\")\n",
    "print(f\"  Non-business hours avg fraud rate: {physical_nonbusiness:.3f}%\")\n",
    "print(f\"  Ratio (non-business/business): {physical_nonbusiness/physical_business:.2f}x\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nâ€¢ Online and physical transactions show DIFFERENT hourly fraud patterns\")\n",
    "print(\"â€¢ This explains the two peaks in overall hourly fraud rate\")\n",
    "print(\"â€¢ Hour of day + transaction type interaction is a valuable feature\")\n",
    "print(\"â€¢ Consider creating time-of-day buckets specific to transaction type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71311766-8fd8-48a3-88ce-22742f1c2487",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Hour correlation findings"
    }
   },
   "source": [
    "### 4.0.3 Key Findings: Hour of Day Correlation\n",
    "\n",
    "**Confirmed: The two peaks in hourly fraud rate are driven by different transaction types!**\n",
    "\n",
    "**Pattern Discovered:**\n",
    "\n",
    "1. **Online Transactions** ðŸŒ\n",
    "   * Higher fraud rates during **evening/night hours** (8 PM - 2 AM)\n",
    "   * Peak fraud during late night when monitoring is reduced\n",
    "   * Non-business hours have **higher fraud rates** than business hours\n",
    "\n",
    "2. **Physical Transactions** ðŸª\n",
    "   * Different peak hours than online\n",
    "   * More stable fraud rates across the day\n",
    "   * Lower overall fraud rates compared to online\n",
    "\n",
    "**Implications for Feature Engineering:**\n",
    "\n",
    "âœ… **DO Create These Features:**\n",
    "* `hour_of_day` (0-23)\n",
    "* `is_business_hours` (9 AM - 6 PM)\n",
    "* `transaction_type` (Online/Physical)\n",
    "* **`hour_x_type` interaction feature** (e.g., \"Online_Night\", \"Physical_Day\")\n",
    "* Time buckets: \"Late Night\" (0-6), \"Morning\" (6-12), \"Afternoon\" (12-18), \"Evening\" (18-24)\n",
    "\n",
    "âœ… **Model Insights:**\n",
    "* Hour of day alone is not enough - must consider transaction type\n",
    "* Online fraud peaks at different times than physical fraud\n",
    "* This interaction explains the complex hourly pattern\n",
    "* Feature importance: `hour_x_type` likely more predictive than `hour` alone\n",
    "\n",
    "**Bottom Line:**\n",
    "The correlation between hour of day and transaction type is **significant and actionable** for fraud detection modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbc49ab3-51dd-4cc4-9d0e-7ba51af25953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.1 Year-Over-Year Fraud Trends\n",
    "\n",
    "**Why This Matters for Fraud Detection:**\n",
    "* Fraud patterns evolve over time as fraudsters adapt\n",
    "* New fraud techniques emerge (e.g., chip cloning, online fraud)\n",
    "* Economic conditions affect fraud rates\n",
    "* Model drift: patterns change, requiring model retraining\n",
    "* Helps identify if training data is representative of current patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e51ac2af-dcc9-4d86-aaf8-1faa9f6fe9d7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Analyze fraud trends by year"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud patterns year-over-year\n",
    "print(\"Year-Over-Year Fraud Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "yearly_fraud = df_time.groupBy('year').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count'),\n",
    "    F.avg('amount').alias('avg_amount'),\n",
    "    F.countDistinct('client_id').alias('unique_customers'),\n",
    "    F.countDistinct('merchant_id').alias('unique_merchants')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "yearly_fraud = yearly_fraud.orderBy('year')\n",
    "print(\"\\nYearly Fraud Statistics:\")\n",
    "yearly_fraud.show(truncate=False)\n",
    "\n",
    "# Calculate year-over-year changes\n",
    "yearly_pd = yearly_fraud.toPandas()\n",
    "yearly_pd['fraud_rate_change'] = yearly_pd['fraud_rate'].pct_change() * 100\n",
    "yearly_pd['volume_change'] = yearly_pd['total_transactions'].pct_change() * 100\n",
    "\n",
    "print(\"\\nYear-Over-Year Changes:\")\n",
    "for idx, row in yearly_pd.iterrows():\n",
    "    if idx > 0:\n",
    "        print(f\"\\n{int(row['year'])}:\")\n",
    "        print(f\"  Fraud Rate Change: {row['fraud_rate_change']:+.1f}%\")\n",
    "        print(f\"  Volume Change: {row['volume_change']:+.1f}%\")\n",
    "        print(f\"  Fraud Count: {int(row['fraud_count']):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d41427b-f4b2-4b5c-80c6-f954f8cd80ba",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualize year-over-year trends"
    }
   },
   "outputs": [],
   "source": [
    "# Comprehensive year-over-year visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Transaction volume over years\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.bar(yearly_pd['year'], yearly_pd['total_transactions'], color='steelblue', alpha=0.7)\n",
    "ax1.set_xlabel('Year', fontsize=11)\n",
    "ax1.set_ylabel('Number of Transactions', fontsize=11)\n",
    "ax1.set_title('Transaction Volume by Year', fontsize=12, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(yearly_pd['total_transactions']):\n",
    "    ax1.text(yearly_pd['year'].iloc[i], v, f'{int(v):,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. Fraud rate over years\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.plot(yearly_pd['year'], yearly_pd['fraud_rate'], marker='o', color='red', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Year', fontsize=11)\n",
    "ax2.set_ylabel('Fraud Rate (%)', fontsize=11)\n",
    "ax2.set_title('Fraud Rate Trend Over Years', fontsize=12, fontweight='bold')\n",
    "ax2.grid(alpha=0.3)\n",
    "for i, v in enumerate(yearly_pd['fraud_rate']):\n",
    "    ax2.text(yearly_pd['year'].iloc[i], v, f'{v:.3f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Fraud count over years\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax3.bar(yearly_pd['year'], yearly_pd['fraud_count'], color='darkred', alpha=0.7)\n",
    "ax3.set_xlabel('Year', fontsize=11)\n",
    "ax3.set_ylabel('Number of Fraud Cases', fontsize=11)\n",
    "ax3.set_title('Fraud Cases by Year', fontsize=12, fontweight='bold')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(yearly_pd['fraud_count']):\n",
    "    ax3.text(yearly_pd['year'].iloc[i], v, f'{int(v):,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 4. Average transaction amount over years\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax4.plot(yearly_pd['year'], yearly_pd['avg_amount'], marker='s', color='green', linewidth=2, markersize=8)\n",
    "ax4.set_xlabel('Year', fontsize=11)\n",
    "ax4.set_ylabel('Average Amount ($)', fontsize=11)\n",
    "ax4.set_title('Average Transaction Amount by Year', fontsize=12, fontweight='bold')\n",
    "ax4.grid(alpha=0.3)\n",
    "for i, v in enumerate(yearly_pd['avg_amount']):\n",
    "    ax4.text(yearly_pd['year'].iloc[i], v, f'${v:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 5. Unique customers and merchants\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "ax5_twin = ax5.twinx()\n",
    "ax5.plot(yearly_pd['year'], yearly_pd['unique_customers'], marker='o', color='blue', linewidth=2, label='Customers')\n",
    "ax5_twin.plot(yearly_pd['year'], yearly_pd['unique_merchants'], marker='s', color='orange', linewidth=2, label='Merchants')\n",
    "ax5.set_xlabel('Year', fontsize=11)\n",
    "ax5.set_ylabel('Unique Customers', color='blue', fontsize=11)\n",
    "ax5_twin.set_ylabel('Unique Merchants', color='orange', fontsize=11)\n",
    "ax5.set_title('Customer and Merchant Growth', fontsize=12, fontweight='bold')\n",
    "ax5.tick_params(axis='y', labelcolor='blue')\n",
    "ax5_twin.tick_params(axis='y', labelcolor='orange')\n",
    "ax5.grid(alpha=0.3)\n",
    "ax5.legend(loc='upper left')\n",
    "ax5_twin.legend(loc='upper right')\n",
    "\n",
    "# 6. Year-over-year change rates\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "if len(yearly_pd) > 1:\n",
    "    x = np.arange(len(yearly_pd) - 1)\n",
    "    width = 0.35\n",
    "    ax6.bar(x - width/2, yearly_pd['fraud_rate_change'].iloc[1:], width, label='Fraud Rate Change', color='red', alpha=0.7)\n",
    "    ax6.bar(x + width/2, yearly_pd['volume_change'].iloc[1:], width, label='Volume Change', color='blue', alpha=0.7)\n",
    "    ax6.set_xlabel('Year', fontsize=11)\n",
    "    ax6.set_ylabel('Change (%)', fontsize=11)\n",
    "    ax6.set_title('Year-Over-Year Changes', fontsize=12, fontweight='bold')\n",
    "    ax6.set_xticks(x)\n",
    "    ax6.set_xticklabels([int(y) for y in yearly_pd['year'].iloc[1:]])\n",
    "    ax6.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax6.legend()\n",
    "    ax6.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Year-Over-Year Fraud Trends Analysis', fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Year-over-year analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6b471ea-d707-47f3-ad9b-5bf27b8800d4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud pattern evolution insights"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze how fraud patterns have evolved\n",
    "print(\"Fraud Pattern Evolution Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Online vs Physical fraud over years\n",
    "print(\"\\n1. Online vs Physical Fraud Evolution:\")\n",
    "online_yearly = df_time.withColumn('is_online', \n",
    "    F.when(F.col('merchant_city') == 'ONLINE', 'Online').otherwise('Physical')\n",
    ").groupBy('year', 'is_online').agg(\n",
    "    F.count('*').alias('total_txns'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_txns') * 100))\n",
    "\n",
    "online_yearly.orderBy('year', 'is_online').show(20, truncate=False)\n",
    "\n",
    "# 2. Cross-border fraud over years\n",
    "print(\"\\n2. Cross-Border Fraud Evolution:\")\n",
    "cross_border_yearly = df_time.groupBy('year', 'is_cross_border').agg(\n",
    "    F.count('*').alias('total_txns'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_txns') * 100))\n",
    "\n",
    "cross_border_yearly.orderBy('year', 'is_cross_border').show(20, truncate=False)\n",
    "\n",
    "# 3. Chip vs Swipe fraud over years\n",
    "print(\"\\n3. Chip vs Swipe Fraud Evolution:\")\n",
    "chip_yearly = df_time.groupBy('year', 'use_chip').agg(\n",
    "    F.count('*').alias('total_txns'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_txns') * 100))\n",
    "\n",
    "chip_yearly.orderBy('year', 'use_chip').show(20, truncate=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY INSIGHTS FOR MODEL BUILDING:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nâ€¢ Check if fraud patterns are stable or evolving over time\")\n",
    "print(\"â€¢ If patterns change significantly, consider:\")\n",
    "print(\"  - Using only recent data for training (e.g., last 1-2 years)\")\n",
    "print(\"  - Adding year/time features to capture temporal trends\")\n",
    "print(\"  - Planning for regular model retraining\")\n",
    "print(\"â€¢ Identify which fraud types are increasing (online, cross-border, etc.)\")\n",
    "print(\"â€¢ Understand if training data represents current fraud landscape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38c5451f-1c59-420a-8eeb-2760f48d895c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.1.1 Critical Observation: Extreme Year-Over-Year Volatility\n",
    "\n",
    "**The fraud rate shows EXTREME volatility across years - this is NOT typical of real-world fraud data.**\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "| Metric | Range | Observation |\n",
    "|--------|-------|-------------|\n",
    "| **Fraud Rate** | 0.004% to 0.309% | **77x difference** between lowest and highest |\n",
    "| **YoY Changes** | -98.6% to +2,333% | Massive swings year-to-year |\n",
    "| **Pattern** | Highly unstable | 2011: 37 cases â†’ 2010: 2,573 cases â†’ 2015: 2,189 cases |\n",
    "\n",
    "**Extreme Year-Over-Year Changes:**\n",
    "* 2011: **-98.6%** (dropped from 2,573 to 37 fraud cases)\n",
    "* 2012: **+2,333%** (jumped from 37 to 923 fraud cases)\n",
    "* 2015: **+224.3%** (jumped from 664 to 2,189 fraud cases)\n",
    "* 2017: **-93.0%** (dropped from 2,448 to 172 fraud cases)\n",
    "* 2018: **+850%** (jumped from 172 to 1,629 fraud cases)\n",
    "\n",
    "**What This Means:**\n",
    "\n",
    "1. **This is Synthetic Data** ðŸŽ¯\n",
    "   * Real-world fraud rates are typically stable (Â±10-20% YoY)\n",
    "   * These extreme swings indicate artificial fraud injection\n",
    "   * Different fraud scenarios added in different years for training diversity\n",
    "\n",
    "2. **Not Temporal Evolution** âš ï¸\n",
    "   * This is NOT fraud patterns evolving over time\n",
    "   * This is a **comprehensive fraud pattern library** distributed across years\n",
    "   * Each year contains different fraud scenarios for model training\n",
    "\n",
    "3. **Implications for Model Training** ðŸ“Š\n",
    "   * âœ… **Use ALL years of data** - each year has unique fraud patterns\n",
    "   * âŒ **Don't filter by recent years** - you'll lose pattern diversity\n",
    "   * âŒ **Don't add year as a feature** - it's not predictive in synthetic data\n",
    "   * âœ… **Focus on behavioral features** - amount, location, chip usage, MCC, etc.\n",
    "\n",
    "**Contrast with Real-World Fraud:**\n",
    "* Real fraud rates: typically 0.1-0.3% with Â±10-20% annual variation\n",
    "* Real patterns: gradual shifts (e.g., online fraud increasing 5-10% annually)\n",
    "* Real evolution: new techniques emerge slowly, not sudden 2,000% spikes\n",
    "\n",
    "**Bottom Line for This Dataset:**\n",
    "**Treat the 10-year span as a comprehensive fraud scenario collection, not a time series.** Use all data for maximum pattern exposure during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e86ad372-b99a-42c2-b989-507fb7069bd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.2 Recommendations for Model Training\n",
    "\n",
    "Based on year-over-year analysis:\n",
    "\n",
    "**Data Selection Strategy:**\n",
    "1. **If fraud patterns are stable** across years:\n",
    "   * Use all available data for training (more data = better model)\n",
    "   * Fraud rate and patterns consistent over time\n",
    "\n",
    "2. **If fraud patterns are evolving** (changing fraud rates, new fraud types):\n",
    "   * **Prioritize recent data** (last 1-2 years) for training\n",
    "   * Use older data cautiously - may not represent current patterns\n",
    "   * Consider time-based features (year, quarter) in the model\n",
    "\n",
    "3. **If specific fraud types are emerging** (e.g., online fraud increasing):\n",
    "   * Ensure training data has sufficient examples of new patterns\n",
    "   * Consider oversampling recent fraud cases\n",
    "   * Plan for regular model retraining (quarterly or semi-annually)\n",
    "\n",
    "**Model Drift Monitoring:**\n",
    "* Track fraud rate changes over time\n",
    "* Monitor if model performance degrades on recent data\n",
    "* Set up alerts for significant pattern shifts\n",
    "* Plan retraining schedule based on pattern stability\n",
    "\n",
    "**Next Steps:**\n",
    "* Review the year-over-year visualizations above\n",
    "* Decide on training data time window\n",
    "* Document any temporal patterns to monitor in production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8d81e84-3595-4301-aa8d-fc8d94f257fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 5. Geographic Patterns\n",
    "Analyze fraud patterns by merchant location (state and city)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "170ad481-4948-41d5-a82f-f1eebe6825bf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud by merchant state"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud rate by merchant state\n",
    "print(\"Fraud Analysis by Merchant State:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "state_fraud = df.groupBy('merchant_state').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "# Filter out null states and get top states by transaction volume\n",
    "state_fraud = state_fraud.filter(F.col('merchant_state').isNotNull())\n",
    "\n",
    "print(\"\\nTop 10 States by Transaction Volume:\")\n",
    "state_fraud.orderBy(F.desc('total_transactions')).show(10)\n",
    "\n",
    "print(\"\\nTop 10 States by Fraud Rate (min 1000 transactions):\")\n",
    "state_fraud.filter(F.col('total_transactions') >= 1000) \\\n",
    "           .orderBy(F.desc('fraud_rate')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c5d2230-8577-4257-b3d3-be3a88922e64",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualize geographic fraud patterns"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize top locations (states and countries)\n",
    "state_pd = state_fraud.filter(F.col('total_transactions') >= 1000).toPandas()\n",
    "top_states = state_pd.nlargest(15, 'total_transactions')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top locations by volume\n",
    "ax1.barh(top_states['merchant_state'], top_states['total_transactions'], color='steelblue', alpha=0.7)\n",
    "ax1.set_xlabel('Number of Transactions')\n",
    "ax1.set_ylabel('Location')\n",
    "ax1.set_title('Top 15 Locations by Transaction Volume')\n",
    "ax1.invert_yaxis()\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Top locations by fraud rate\n",
    "top_fraud_states = state_pd.nlargest(15, 'fraud_rate')\n",
    "ax2.barh(top_fraud_states['merchant_state'], top_fraud_states['fraud_rate'], color='red', alpha=0.7)\n",
    "ax2.set_xlabel('Fraud Rate (%)')\n",
    "ax2.set_ylabel('Location')\n",
    "ax2.set_title('Top 15 Locations by Fraud Rate (min 1000 txns)')\n",
    "ax2.invert_yaxis()\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Geographic analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cddda58d-af2f-4eb6-b662-331c91ff745d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Online vs physical location fraud"
    }
   },
   "outputs": [],
   "source": [
    "# Compare online vs physical merchant locations\n",
    "print(\"Online vs Physical Merchant Fraud Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "online_fraud = df.withColumn('is_online', \n",
    "    F.when(F.col('merchant_city') == 'ONLINE', 'Online').otherwise('Physical')\n",
    ").groupBy('is_online').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "online_fraud.show()\n",
    "\n",
    "# Visualize\n",
    "online_pd = online_fraud.toPandas()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Transaction volume\n",
    "ax1.bar(online_pd['is_online'], online_pd['total_transactions'], color=['steelblue', 'orange'], alpha=0.7)\n",
    "ax1.set_ylabel('Number of Transactions')\n",
    "ax1.set_title('Transaction Volume: Online vs Physical')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(online_pd['total_transactions']):\n",
    "    ax1.text(i, v, f'{v:,}', ha='center', va='bottom')\n",
    "\n",
    "# Fraud rate\n",
    "ax2.bar(online_pd['is_online'], online_pd['fraud_rate'], color=['red', 'darkred'], alpha=0.7)\n",
    "ax2.set_ylabel('Fraud Rate (%)')\n",
    "ax2.set_title('Fraud Rate: Online vs Physical')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(online_pd['fraud_rate']):\n",
    "    ax2.text(i, v, f'{v:.3f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9508dda3-26b1-4f37-ac16-0df249899a0b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Italy cross-border fraud section"
    }
   },
   "source": [
    "---\n",
    "## 5.1 Italy Cross-Border Fraud Analysis\n",
    "Deep dive into the Italy fraud pattern - why does Italy have the highest fraud concentration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fbf0a86-d553-4c48-8b59-a61a45d19289",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Italy fraud statistics"
    }
   },
   "outputs": [],
   "source": [
    "# Detailed analysis of Italy fraud pattern\n",
    "print(\"Italy Cross-Border Fraud Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compare Italy vs Spain vs other locations\n",
    "state_analysis = df.groupBy('merchant_state').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count'),\n",
    "    F.sum(F.when(F.col('label') == 'No', 1).otherwise(0)).alias('legit_count'),\n",
    "    F.avg('amount').alias('avg_amount')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "print(\"\\nSpain vs Italy Comparison:\")\n",
    "spain_italy = state_analysis.filter(F.col('merchant_state').isin(['Spain', 'Italy']))\n",
    "spain_italy.orderBy('merchant_state').show(truncate=False)\n",
    "\n",
    "print(\"\\nTop 10 Locations by Fraud Count:\")\n",
    "state_analysis.filter(F.col('merchant_state').isNotNull()) \\\n",
    "              .orderBy(F.desc('fraud_count')).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7834403-289d-4ebb-9396-27a6d5e50f76",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Italy fraud characteristics"
    }
   },
   "outputs": [],
   "source": [
    "# Deep dive into Italy transaction characteristics\n",
    "italy_txns = df.filter(F.col('merchant_state') == 'Italy')\n",
    "\n",
    "print(\"Italy Transaction Characteristics:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compare fraud vs legitimate in Italy\n",
    "print(\"\\n1. Fraud vs Legitimate Comparison in Italy:\")\n",
    "italy_comparison = italy_txns.groupBy('label').agg(\n",
    "    F.count('*').alias('count'),\n",
    "    F.avg('amount').alias('avg_amount'),\n",
    "    F.min('amount').alias('min_amount'),\n",
    "    F.max('amount').alias('max_amount'),\n",
    "    F.countDistinct('merchant_city').alias('unique_cities'),\n",
    "    F.countDistinct('client_id').alias('unique_clients')\n",
    ")\n",
    "italy_comparison.show(truncate=False)\n",
    "\n",
    "# Check chip usage patterns\n",
    "print(\"\\n2. Chip vs Swipe Usage in Italy:\")\n",
    "italy_txns.groupBy('label', 'use_chip').count().orderBy('label', 'use_chip').show(truncate=False)\n",
    "\n",
    "# Check merchant cities\n",
    "print(\"\\n3. Merchant Cities in Italy:\")\n",
    "italy_txns.groupBy('merchant_city', 'label').count().orderBy(F.desc('count')).show(10)\n",
    "\n",
    "# Overall fraud context\n",
    "total_fraud = df.filter(F.col('label') == 'Yes').count()\n",
    "italy_fraud = italy_txns.filter(F.col('label') == 'Yes').count()\n",
    "print(f\"\\n4. Italy's Share of Total Fraud:\")\n",
    "print(f\"   Total fraud cases: {total_fraud:,}\")\n",
    "print(f\"   Italy fraud cases: {italy_fraud:,}\")\n",
    "print(f\"   Italy as % of total fraud: {(italy_fraud/total_fraud*100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d2504a0-38e1-46e5-a4e1-275b46c31b94",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualize Italy fraud pattern"
    }
   },
   "outputs": [],
   "source": [
    "# Comprehensive visualization of Italy fraud pattern\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Italy's share of total fraud\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "fraud_breakdown = ['Italy Fraud', 'Other Fraud']\n",
    "fraud_counts = [3061, 13332-3061]\n",
    "colors = ['#e74c3c', '#95a5a6']\n",
    "ax1.pie(fraud_counts, labels=fraud_breakdown, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "ax1.set_title('Italy\\'s Share of Total Fraud Cases', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2. Italy fraud rate vs other locations\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "locations = ['Italy', 'Spain', 'US States\\n(avg)', 'Haiti']\n",
    "fraud_rates = [65.0, 0.0, 0.05, 95.8]\n",
    "colors_bar = ['#e74c3c', '#27ae60', '#3498db', '#c0392b']\n",
    "bars = ax2.bar(locations, fraud_rates, color=colors_bar, alpha=0.7)\n",
    "ax2.set_ylabel('Fraud Rate (%)', fontsize=10)\n",
    "ax2.set_title('Fraud Rate by Location', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylim(0, 100)\n",
    "for i, (bar, rate) in enumerate(zip(bars, fraud_rates)):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "             f'{rate:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Transaction volume comparison\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "locations_vol = ['Italy', 'Spain', 'Top US State\\n(CA)']\n",
    "volumes = [4706, 1109, 956356]\n",
    "ax3.bar(locations_vol, volumes, color=['#e74c3c', '#27ae60', '#3498db'], alpha=0.7)\n",
    "ax3.set_ylabel('Number of Transactions', fontsize=10)\n",
    "ax3.set_title('Transaction Volume by Location', fontsize=12, fontweight='bold')\n",
    "ax3.set_yscale('log')\n",
    "for i, v in enumerate(volumes):\n",
    "    ax3.text(i, v, f'{v:,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 4. Italy fraud characteristics - Chip vs Swipe\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "chip_types = ['Chip\\nTransaction', 'Swipe\\nTransaction']\n",
    "fraud_chip = [2786, 275]\n",
    "legit_chip = [757, 888]\n",
    "x = np.arange(len(chip_types))\n",
    "width = 0.35\n",
    "bars1 = ax4.bar(x - width/2, fraud_chip, width, label='Fraud', color='#e74c3c', alpha=0.7)\n",
    "bars2 = ax4.bar(x + width/2, legit_chip, width, label='Legitimate', color='#27ae60', alpha=0.7)\n",
    "ax4.set_ylabel('Number of Transactions', fontsize=10)\n",
    "ax4.set_title('Italy: Chip vs Swipe Usage', fontsize=12, fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(chip_types)\n",
    "ax4.legend()\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Amount comparison\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "amount_categories = ['Italy\\nFraud', 'Italy\\nLegitimate', 'Overall\\nFraud', 'Overall\\nLegitimate']\n",
    "avg_amounts = [82.64, 35.31, 110.23, 40.0]\n",
    "colors_amt = ['#e74c3c', '#27ae60', '#e67e22', '#2ecc71']\n",
    "bars = ax5.bar(amount_categories, avg_amounts, color=colors_amt, alpha=0.7)\n",
    "ax5.set_ylabel('Average Amount ($)', fontsize=10)\n",
    "ax5.set_title('Average Transaction Amount Comparison', fontsize=12, fontweight='bold')\n",
    "for bar, amt in zip(bars, avg_amounts):\n",
    "    ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "             f'${amt:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "ax5.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 6. Summary text box\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "ax6.axis('off')\n",
    "summary_text = \"\"\"\n",
    "KEY FINDINGS: Why Italy Has High Fraud\n",
    "\n",
    "1. CROSS-BORDER FRAUD PATTERN\n",
    "   â€¢ US customers' cards used in Italy\n",
    "   â€¢ All transactions in Rome only\n",
    "   â€¢ 65% fraud rate (3,061 of 4,706 txns)\n",
    "\n",
    "2. FRAUD CHARACTERISTICS\n",
    "   â€¢ 91% use chip technology (2,786 chip txns)\n",
    "   â€¢ Lower avg amount: $82.64 vs $110.23 overall\n",
    "   â€¢ No dark web exposure detected\n",
    "   â€¢ Most have no transaction errors\n",
    "\n",
    "3. SCALE OF IMPACT\n",
    "   â€¢ Italy = 23% of ALL fraud cases\n",
    "   â€¢ Only 0.05% of total transactions\n",
    "   â€¢ Highly concentrated fraud activity\n",
    "\n",
    "4. LIKELY EXPLANATION\n",
    "   â€¢ Tourist/travel fraud in Rome\n",
    "   â€¢ Card skimming or cloning\n",
    "   â€¢ Cross-border makes detection harder\n",
    "   â€¢ US-based synthetic training dataset\n",
    "\"\"\"\n",
    "ax6.text(0.05, 0.95, summary_text, transform=ax6.transAxes, \n",
    "         fontsize=9, verticalalignment='top', family='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.suptitle('Italy Fraud Analysis: Cross-Border Fraud Pattern (US-Based Dataset)', \n",
    "             fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Italy cross-border fraud analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91239e40-9e1f-4233-8b0e-fd2003783a5d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Geographic categorization section"
    }
   },
   "source": [
    "---\n",
    "## 5.2 Geographic Categorization Analysis\n",
    "Analyze the `location_type` and `is_cross_border` features added in the Silver layer to understand the true geographic distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "324cede8-7425-434a-af4b-2681c83a0650",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Location type distribution"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze location_type distribution\n",
    "print(\"Geographic Categorization Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. Location Type Distribution:\")\n",
    "location_dist = df.groupBy('location_type').agg(\n",
    "    F.count('*').alias('total_txns'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count'),\n",
    "    F.countDistinct('client_id').alias('unique_customers')\n",
    ").withColumn('fraud_rate_pct', F.round((F.col('fraud_count') / F.col('total_txns') * 100), 3))\n",
    "\n",
    "location_dist.orderBy(F.desc('total_txns')).show(truncate=False)\n",
    "\n",
    "# Calculate percentages\n",
    "total = df.count()\n",
    "print(f\"\\nTotal transactions: {total:,}\")\n",
    "for row in location_dist.collect():\n",
    "    pct = (row['total_txns'] / total * 100)\n",
    "    print(f\"{row['location_type']:15} {row['total_txns']:>10,} txns ({pct:>5.1f}%)\")\n",
    "\n",
    "print(\"\\n2. Cross-Border Transaction Summary:\")\n",
    "df.groupBy('is_cross_border').agg(\n",
    "    F.count('*').alias('total_txns'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate_pct', F.round((F.col('fraud_count') / F.col('total_txns') * 100), 3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91fda7fb-9c43-400c-9fac-6575a99d97c4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualize geographic distribution"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize geographic distribution and fraud patterns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Transaction volume by location type\n",
    "loc_pd = location_dist.toPandas()\n",
    "ax1 = axes[0, 0]\n",
    "colors_loc = ['#3498db', '#2ecc71', '#e74c3c', '#95a5a6']\n",
    "ax1.bar(loc_pd['location_type'], loc_pd['total_txns'], color=colors_loc, alpha=0.7)\n",
    "ax1.set_ylabel('Number of Transactions', fontsize=11)\n",
    "ax1.set_title('Transaction Volume by Location Type', fontsize=12, fontweight='bold')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(loc_pd['total_txns']):\n",
    "    ax1.text(i, v, f'{v:,.0f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. Fraud rate by location type\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(loc_pd['location_type'], loc_pd['fraud_rate_pct'], color=colors_loc, alpha=0.7)\n",
    "ax2.set_ylabel('Fraud Rate (%)', fontsize=11)\n",
    "ax2.set_title('Fraud Rate by Location Type', fontsize=12, fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(loc_pd['fraud_rate_pct']):\n",
    "    ax2.text(i, v, f'{v:.3f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Pie chart - Transaction distribution\n",
    "ax3 = axes[1, 0]\n",
    "ax3.pie(loc_pd['total_txns'], labels=loc_pd['location_type'], autopct='%1.1f%%', \n",
    "        colors=colors_loc, startangle=90)\n",
    "ax3.set_title('Transaction Distribution by Location Type', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 4. Top international locations (fraud cases)\n",
    "ax4 = axes[1, 1]\n",
    "intl_fraud = df.filter((F.col('location_type') == 'International') & (F.col('label') == 'Yes')) \\\n",
    "               .groupBy('merchant_state').count().orderBy(F.desc('count')).limit(10).toPandas()\n",
    "ax4.barh(intl_fraud['merchant_state'], intl_fraud['count'], color='#e74c3c', alpha=0.7)\n",
    "ax4.set_xlabel('Fraud Cases', fontsize=11)\n",
    "ax4.set_title('Top 10 International Locations (Fraud Cases)', fontsize=12, fontweight='bold')\n",
    "ax4.invert_yaxis()\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "for i, v in enumerate(intl_fraud['count']):\n",
    "    ax4.text(v, i, f' {v:,}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Geographic categorization analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "239d3690-af19-41aa-b6dc-5fd57d6f7c90",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cross-border fraud insights"
    }
   },
   "outputs": [],
   "source": [
    "# Deep dive into cross-border fraud\n",
    "print(\"Cross-Border Fraud Deep Dive:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compare domestic vs cross-border\n",
    "print(\"\\n1. Domestic vs Cross-Border Comparison:\")\n",
    "cross_border_analysis = df.groupBy('is_cross_border').agg(\n",
    "    F.count('*').alias('total_txns'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count'),\n",
    "    F.avg('amount').alias('avg_amount'),\n",
    "    F.countDistinct('client_id').alias('unique_customers')\n",
    ").withColumn('fraud_rate_pct', F.round((F.col('fraud_count') / F.col('total_txns') * 100), 3))\n",
    "\n",
    "cross_border_analysis.show(truncate=False)\n",
    "\n",
    "# International locations breakdown\n",
    "print(\"\\n2. International Locations Breakdown:\")\n",
    "intl_breakdown = df.filter(F.col('location_type') == 'International') \\\n",
    "                   .groupBy('merchant_state', 'merchant_city').agg(\n",
    "                       F.count('*').alias('total_txns'),\n",
    "                       F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    "                   ).withColumn('fraud_rate_pct', F.round((F.col('fraud_count') / F.col('total_txns') * 100), 2))\n",
    "\n",
    "intl_breakdown.orderBy(F.desc('fraud_count')).show(10, truncate=False)\n",
    "\n",
    "print(\"\\n3. Key Insights:\")\n",
    "print(\"   â€¢ International transactions have significantly higher fraud rates\")\n",
    "print(\"   â€¢ Italy (Rome) is the primary international fraud hotspot\")\n",
    "print(\"   â€¢ Cross-border flag is a strong fraud indicator for modeling\")\n",
    "print(\"   â€¢ Most transactions (87.5%) are domestic US transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "955b19d7-172e-4101-bcbf-b8e3f1db18fd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Haiti outlier note"
    }
   },
   "source": [
    "### 5.2.1 Important Note: Haiti Outlier\n",
    "\n",
    "**Haiti has the HIGHEST fraud rate in the dataset (95.8%) but is excluded from \"Top 15 Locations by Fraud Rate\" visualizations.**\n",
    "\n",
    "**Why Haiti is Filtered Out:**\n",
    "* **Volume**: Only **264 transactions** (vs Italy's 4,706)\n",
    "* **Threshold**: Geographic analysis uses **minimum 1,000 transactions** for statistical significance\n",
    "* **Fraud Cases**: 253 out of 264 transactions are fraudulent\n",
    "\n",
    "**Comparison:**\n",
    "\n",
    "| Location | Transactions | Fraud Cases | Fraud Rate |\n",
    "|----------|--------------|-------------|------------|\n",
    "| **Haiti** | 264 | 253 | **95.8%** ðŸ”´ |\n",
    "| **Italy** | 4,706 | 3,061 | **65.0%** |\n",
    "| **Tuvalu** | 5 | 5 | **100%** |\n",
    "\n",
    "**Why This Filtering Makes Sense:**\n",
    "* **Statistical Significance**: Small samples can have extreme rates due to random variation\n",
    "* **Practical Relevance**: Focus on patterns with enough data to be actionable\n",
    "* **Model Training**: Low-volume patterns may not generalize well\n",
    "\n",
    "**Interpretation:**\n",
    "* Haiti likely represents a **specific fraud incident** or compromised merchant\n",
    "* Too few transactions to establish a reliable pattern\n",
    "* Could be a single fraud ring or data anomaly\n",
    "\n",
    "**For Modeling:**\n",
    "* âœ… Use `is_cross_border` feature to capture both Italy and Haiti patterns\n",
    "* âš ï¸ Haiti alone is not a reliable predictor due to low volume\n",
    "* âœ… Italy provides sufficient data for cross-border fraud detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c0955d1-76bd-4dd1-a37b-03cb4beb1bb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 6. MCC (Merchant Category Code) Analysis\n",
    "Identify high-risk merchant categories and fraud patterns by business type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6770ab9-8559-4a7d-a78e-5beffde811af",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud by MCC category"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud rate by MCC category\n",
    "print(\"Fraud Analysis by MCC Category:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "mcc_fraud = df.groupBy('mcc', 'mcc_description').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "# Filter out null MCC and get categories with significant volume\n",
    "mcc_fraud = mcc_fraud.filter(F.col('mcc').isNotNull())\n",
    "\n",
    "print(\"\\nTop 10 MCC Categories by Transaction Volume:\")\n",
    "mcc_fraud.orderBy(F.desc('total_transactions')).show(10, truncate=False)\n",
    "\n",
    "print(\"\\nTop 10 MCC Categories by Fraud Rate (min 1000 transactions):\")\n",
    "mcc_fraud.filter(F.col('total_transactions') >= 1000) \\\n",
    "         .orderBy(F.desc('fraud_rate')).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbe17059-934a-4d25-838c-0e51148077cd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualize MCC fraud patterns"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize MCC patterns\n",
    "mcc_pd = mcc_fraud.filter(F.col('total_transactions') >= 1000).toPandas()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "# Top 15 MCC by volume\n",
    "top_mcc_volume = mcc_pd.nlargest(15, 'total_transactions')\n",
    "axes[0].barh(top_mcc_volume['mcc_description'], top_mcc_volume['total_transactions'], color='steelblue', alpha=0.7)\n",
    "axes[0].set_xlabel('Number of Transactions')\n",
    "axes[0].set_title('Top 15 Merchant Categories by Transaction Volume')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Top 15 MCC by fraud rate\n",
    "top_mcc_fraud = mcc_pd.nlargest(15, 'fraud_rate')\n",
    "axes[1].barh(top_mcc_fraud['mcc_description'], top_mcc_fraud['fraud_rate'], color='red', alpha=0.7)\n",
    "axes[1].set_xlabel('Fraud Rate (%)')\n",
    "axes[1].set_title('Top 15 Merchant Categories by Fraud Rate (min 1000 txns)')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… MCC analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2f9c646-1f14-4a13-9154-5df66310a043",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "MCC fraud summary statistics"
    }
   },
   "outputs": [],
   "source": [
    "# Summary statistics for MCC fraud rates\n",
    "print(\"MCC Fraud Rate Summary Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "mcc_stats = mcc_fraud.filter(F.col('total_transactions') >= 100).select('fraud_rate').summary()\n",
    "mcc_stats.show()\n",
    "\n",
    "# Identify high-risk vs low-risk categories\n",
    "avg_fraud_rate = mcc_fraud.filter(F.col('total_transactions') >= 100).agg(F.avg('fraud_rate')).collect()[0][0]\n",
    "\n",
    "print(f\"\\nAverage Fraud Rate across MCC categories: {avg_fraud_rate:.3f}%\")\n",
    "print(f\"\\nHigh-Risk Categories (fraud rate > {avg_fraud_rate:.3f}%):\")\n",
    "mcc_fraud.filter((F.col('total_transactions') >= 100) & (F.col('fraud_rate') > avg_fraud_rate)) \\\n",
    "         .orderBy(F.desc('fraud_rate')).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee393a51-02e7-4d20-8388-5b4184674c8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 7. User Demographics Analysis\n",
    "Analyze fraud patterns by user characteristics: age, income, credit score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7aae445-cbe0-447b-abc3-a4b71a816fe1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud by age groups"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud by age groups\n",
    "print(\"Fraud Analysis by Age Groups:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create age bins\n",
    "age_fraud = df.withColumn('age_group',\n",
    "    F.when(F.col('current_age') < 25, '18-24')\n",
    "     .when(F.col('current_age') < 35, '25-34')\n",
    "     .when(F.col('current_age') < 45, '35-44')\n",
    "     .when(F.col('current_age') < 55, '45-54')\n",
    "     .when(F.col('current_age') < 65, '55-64')\n",
    "     .otherwise('65+')\n",
    ").groupBy('age_group').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count'),\n",
    "    F.avg('current_age').alias('avg_age')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "age_fraud = age_fraud.orderBy('avg_age')\n",
    "age_fraud.show()\n",
    "\n",
    "# Visualize\n",
    "age_pd = age_fraud.toPandas()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Transaction volume by age\n",
    "ax1.bar(age_pd['age_group'], age_pd['total_transactions'], color='steelblue', alpha=0.7)\n",
    "ax1.set_xlabel('Age Group')\n",
    "ax1.set_ylabel('Number of Transactions')\n",
    "ax1.set_title('Transaction Volume by Age Group')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Fraud rate by age\n",
    "ax2.plot(age_pd['age_group'], age_pd['fraud_rate'], marker='o', color='red', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Age Group')\n",
    "ax2.set_ylabel('Fraud Rate (%)')\n",
    "ax2.set_title('Fraud Rate by Age Group')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f29baa7f-3b51-48cb-b167-e24694015080",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud by income levels"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud by income levels\n",
    "print(\"Fraud Analysis by Income Levels:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create income bins\n",
    "income_fraud = df.withColumn('income_group',\n",
    "    F.when(F.col('yearly_income') < 30000, 'Under $30K')\n",
    "     .when(F.col('yearly_income') < 50000, '$30K-$50K')\n",
    "     .when(F.col('yearly_income') < 75000, '$50K-$75K')\n",
    "     .when(F.col('yearly_income') < 100000, '$75K-$100K')\n",
    "     .when(F.col('yearly_income') < 150000, '$100K-$150K')\n",
    "     .otherwise('Over $150K')\n",
    ").groupBy('income_group').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count'),\n",
    "    F.avg('yearly_income').alias('avg_income')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "income_fraud = income_fraud.orderBy('avg_income')\n",
    "income_fraud.show()\n",
    "\n",
    "# Visualize\n",
    "income_pd = income_fraud.toPandas()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Transaction volume by income\n",
    "ax1.bar(income_pd['income_group'], income_pd['total_transactions'], color='green', alpha=0.7)\n",
    "ax1.set_xlabel('Income Group')\n",
    "ax1.set_ylabel('Number of Transactions')\n",
    "ax1.set_title('Transaction Volume by Income Level')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Fraud rate by income\n",
    "ax2.plot(income_pd['income_group'], income_pd['fraud_rate'], marker='o', color='red', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Income Group')\n",
    "ax2.set_ylabel('Fraud Rate (%)')\n",
    "ax2.set_title('Fraud Rate by Income Level')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7da4984b-0b4e-4d75-aa7c-5637fc2c1390",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud by credit score"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud by credit score ranges\n",
    "print(\"Fraud Analysis by Credit Score:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create credit score bins\n",
    "credit_fraud = df.withColumn('credit_group',\n",
    "    F.when(F.col('credit_score') < 580, 'Poor (<580)')\n",
    "     .when(F.col('credit_score') < 670, 'Fair (580-669)')\n",
    "     .when(F.col('credit_score') < 740, 'Good (670-739)')\n",
    "     .when(F.col('credit_score') < 800, 'Very Good (740-799)')\n",
    "     .otherwise('Excellent (800+)')\n",
    ").groupBy('credit_group').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count'),\n",
    "    F.avg('credit_score').alias('avg_credit_score')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "credit_fraud = credit_fraud.orderBy('avg_credit_score')\n",
    "credit_fraud.show()\n",
    "\n",
    "# Visualize\n",
    "credit_pd = credit_fraud.toPandas()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Transaction volume by credit score\n",
    "ax1.bar(credit_pd['credit_group'], credit_pd['total_transactions'], color='purple', alpha=0.7)\n",
    "ax1.set_xlabel('Credit Score Range')\n",
    "ax1.set_ylabel('Number of Transactions')\n",
    "ax1.set_title('Transaction Volume by Credit Score')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Fraud rate by credit score\n",
    "ax2.plot(credit_pd['credit_group'], credit_pd['fraud_rate'], marker='o', color='red', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Credit Score Range')\n",
    "ax2.set_ylabel('Fraud Rate (%)')\n",
    "ax2.set_title('Fraud Rate by Credit Score')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Demographics analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12c51dac-91f9-49a5-b880-75517f8b525b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 8. Card Characteristics Analysis\n",
    "Analyze fraud patterns by card type, brand, chip usage, and dark web exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab169926-6c3d-43e1-8ef6-dd40853328f4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud by card type and brand"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud by card type\n",
    "print(\"Fraud Analysis by Card Type:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "card_type_fraud = df.groupBy('card_type').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "card_type_fraud.orderBy(F.desc('fraud_rate')).show()\n",
    "\n",
    "# Analyze fraud by card brand\n",
    "print(\"\\nFraud Analysis by Card Brand:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "card_brand_fraud = df.groupBy('card_brand').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "card_brand_fraud.orderBy(F.desc('fraud_rate')).show()\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Card type fraud rate\n",
    "card_type_pd = card_type_fraud.toPandas()\n",
    "ax1.bar(card_type_pd['card_type'], card_type_pd['fraud_rate'], color='orange', alpha=0.7)\n",
    "ax1.set_xlabel('Card Type')\n",
    "ax1.set_ylabel('Fraud Rate (%)')\n",
    "ax1.set_title('Fraud Rate by Card Type')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Card brand fraud rate\n",
    "card_brand_pd = card_brand_fraud.toPandas()\n",
    "ax2.bar(card_brand_pd['card_brand'], card_brand_pd['fraud_rate'], color='purple', alpha=0.7)\n",
    "ax2.set_xlabel('Card Brand')\n",
    "ax2.set_ylabel('Fraud Rate (%)')\n",
    "ax2.set_title('Fraud Rate by Card Brand')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47f023b1-30cd-49da-b52b-4ec8420d41be",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Chip vs swipe transaction fraud"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud by chip usage\n",
    "print(\"Fraud Analysis: Chip vs Swipe Transactions:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "chip_fraud = df.groupBy('use_chip').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "chip_fraud.orderBy(F.desc('fraud_rate')).show()\n",
    "\n",
    "# Visualize\n",
    "chip_pd = chip_fraud.toPandas()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Transaction volume\n",
    "ax1.bar(chip_pd['use_chip'], chip_pd['total_transactions'], color=['steelblue', 'orange', 'green'], alpha=0.7)\n",
    "ax1.set_xlabel('Transaction Type')\n",
    "ax1.set_ylabel('Number of Transactions')\n",
    "ax1.set_title('Transaction Volume by Type')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Fraud rate\n",
    "ax2.bar(chip_pd['use_chip'], chip_pd['fraud_rate'], color=['red', 'darkred', 'crimson'], alpha=0.7)\n",
    "ax2.set_xlabel('Transaction Type')\n",
    "ax2.set_ylabel('Fraud Rate (%)')\n",
    "ax2.set_title('Fraud Rate by Transaction Type')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ceb8fd6-4bb1-4a14-a1fc-ef7ea179f2ef",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Dark web exposure analysis"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud for cards on dark web\n",
    "print(\"Fraud Analysis: Card Dark Web Exposure:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "dark_web_fraud = df.groupBy('card_on_dark_web').agg(\n",
    "    F.count('*').alias('total_transactions'),\n",
    "    F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    ").withColumn('fraud_rate', (F.col('fraud_count') / F.col('total_transactions') * 100))\n",
    "\n",
    "dark_web_fraud.orderBy(F.desc('fraud_rate')).show()\n",
    "\n",
    "# Visualize\n",
    "dark_web_pd = dark_web_fraud.toPandas()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Transaction volume\n",
    "ax1.bar(dark_web_pd['card_on_dark_web'], dark_web_pd['total_transactions'], color=['green', 'red'], alpha=0.7)\n",
    "ax1.set_xlabel('Card on Dark Web')\n",
    "ax1.set_ylabel('Number of Transactions')\n",
    "ax1.set_title('Transaction Volume by Dark Web Status')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(dark_web_pd['total_transactions']):\n",
    "    ax1.text(i, v, f'{v:,}', ha='center', va='bottom')\n",
    "\n",
    "# Fraud rate\n",
    "ax2.bar(dark_web_pd['card_on_dark_web'], dark_web_pd['fraud_rate'], color=['green', 'darkred'], alpha=0.7)\n",
    "ax2.set_xlabel('Card on Dark Web')\n",
    "ax2.set_ylabel('Fraud Rate (%)')\n",
    "ax2.set_title('Fraud Rate by Dark Web Status')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(dark_web_pd['fraud_rate']):\n",
    "    ax2.text(i, v, f'{v:.3f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Card characteristics analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74483164-316c-4d63-b29e-6d9239f0b232",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 9. Feature Correlations & Key Insights\n",
    "Identify which features correlate most with fraud for model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f724e73d-a896-4258-88cc-86e77ef87aff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Numeric feature correlations"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze correlations for numeric features\n",
    "print(\"Correlation Analysis with Fraud Label:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Convert label to numeric for correlation\n",
    "df_corr = df.withColumn('is_fraud', F.when(F.col('label') == 'Yes', 1).otherwise(0))\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_features = ['amount', 'current_age', 'credit_score', 'yearly_income', 'total_debt', \n",
    "                    'num_credit_cards', 'num_cards_issued', 'year_pin_last_changed']\n",
    "\n",
    "# Calculate correlations\n",
    "correlations = []\n",
    "for feature in numeric_features:\n",
    "    if feature in df_corr.columns:\n",
    "        corr = df_corr.stat.corr('is_fraud', feature)\n",
    "        correlations.append((feature, corr))\n",
    "\n",
    "# Sort by absolute correlation\n",
    "correlations_sorted = sorted(correlations, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"\\nFeature Correlations with Fraud (sorted by absolute value):\")\n",
    "for feature, corr in correlations_sorted:\n",
    "    print(f\"{feature:30} {corr:>10.4f}\")\n",
    "\n",
    "# Visualize\n",
    "import pandas as pd\n",
    "corr_df = pd.DataFrame(correlations_sorted, columns=['Feature', 'Correlation'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['red' if x < 0 else 'green' for x in corr_df['Correlation']]\n",
    "ax.barh(corr_df['Feature'], corr_df['Correlation'], color=colors, alpha=0.7)\n",
    "ax.set_xlabel('Correlation with Fraud')\n",
    "ax.set_title('Feature Correlations with Fraud Label')\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f581cb37-0f78-485d-866a-663ff333cf35",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Categorical feature fraud rates"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze fraud rates for key categorical features\n",
    "print(\"Fraud Rates by Categorical Features:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "categorical_features = ['use_chip', 'card_type', 'card_brand', 'has_chip', 'card_on_dark_web', 'gender']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature in df.columns:\n",
    "        print(f\"\\n{feature.upper()}:\")\n",
    "        feature_fraud = df.groupBy(feature).agg(\n",
    "            F.count('*').alias('count'),\n",
    "            F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    "        ).withColumn('fraud_rate', (F.col('fraud_count') / F.col('count') * 100))\n",
    "        \n",
    "        feature_fraud.orderBy(F.desc('fraud_rate')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c813500e-5b99-47fa-a1eb-ca9743587c8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 10. Feature Importance Summary for Modeling\n",
    "\n",
    "Based on comprehensive EDA analysis, here are the recommended features prioritized by predictive power:\n",
    "\n",
    "### ðŸŽ¯ **Tier 1: High Priority Features (Critical)**\n",
    "\n",
    "| Feature | Why Important | Evidence |\n",
    "|---------|---------------|----------|\n",
    "| `is_cross_border` | 43x fraud rate difference | 4.85% vs 0.11% fraud rate |\n",
    "| `location_type` | International 43x riskier | US_State: 0.016%, International: 4.85% |\n",
    "| `merchant_state` | Specific high-risk locations | Italy: 65%, Haiti: 95.8% fraud rate |\n",
    "| `hour_x_type` | Interaction feature | Online 10 AM: 1.80%, Physical 6 PM: 0.13% |\n",
    "| `card_on_dark_web` | Direct fraud indicator | Strong correlation with fraud |\n",
    "| `mcc` / `mcc_description` | High-risk merchant categories | Certain categories show elevated fraud |\n",
    "\n",
    "### ðŸŸ¡ **Tier 2: Medium Priority Features (Important)**\n",
    "\n",
    "| Feature | Why Important | Evidence |\n",
    "|---------|---------------|----------|\n",
    "| `amount` | Fraud transactions higher | Fraud avg: $110, Legitimate avg: $43 |\n",
    "| `hour_of_day` | Time-based patterns | Peak fraud hours identified |\n",
    "| `use_chip` | Chip vs swipe fraud patterns | Different fraud rates by method |\n",
    "| `day_of_week` | Weekly patterns | Variation across days |\n",
    "| `merchant_city` | Online vs physical | Online: 0.84%, Physical: 0.016% |\n",
    "| `credit_score` | Risk correlation | Lower scores may correlate with fraud |\n",
    "| `yearly_income` | Demographic indicator | Income-based patterns |\n",
    "\n",
    "### ðŸŸ¢ **Tier 3: Low Priority Features (Supplementary)**\n",
    "\n",
    "| Feature | Why Lower Priority | Notes |\n",
    "|---------|-------------------|-------|\n",
    "| `month` | Weak seasonal patterns | Minimal variation across months |\n",
    "| `gender` | Minimal correlation | No strong fraud pattern |\n",
    "| `card_type` / `card_brand` | Moderate variation | Some signal but not primary |\n",
    "| `current_age` | Weak correlation | Age groups show similar fraud rates |\n",
    "\n",
    "### âŒ **Features to EXCLUDE:**\n",
    "\n",
    "| Feature | Why Exclude | Reason |\n",
    "|---------|-------------|--------|\n",
    "| `year` | Not predictive | Synthetic data with artificial patterns |\n",
    "| `tx_id`, `client_id`, `card_id` | Identifiers only | No predictive value |\n",
    "| `date`, `tx_ts` | Use derived features | Extract hour, day, month instead |\n",
    "\n",
    "### ðŸ› ï¸ **Recommended Feature Engineering:**\n",
    "\n",
    "**Create These New Features:**\n",
    "1. **`hour_x_type`**: Interaction between hour and transaction type\n",
    "   * Example: \"Online_Morning\", \"Physical_Evening\"\n",
    "\n",
    "2. **`is_business_hours`**: Boolean flag for 9 AM - 6 PM\n",
    "   * Different fraud patterns during business hours\n",
    "\n",
    "3. **`time_bucket`**: Categorical time periods\n",
    "   * \"Late Night\" (0-6), \"Morning\" (6-12), \"Afternoon\" (12-18), \"Evening\" (18-24)\n",
    "\n",
    "4. **`is_high_risk_location`**: Flag for Italy, Haiti, other high-risk locations\n",
    "   * Simplifies geographic risk assessment\n",
    "\n",
    "5. **`amount_zscore`**: Standardized transaction amount\n",
    "   * Helps identify unusual amounts\n",
    "\n",
    "6. **`is_weekend`**: Boolean for Saturday/Sunday\n",
    "   * Weekend vs weekday patterns\n",
    "\n",
    "### ðŸ“Š **Model Architecture Recommendations:**\n",
    "\n",
    "**Best Algorithms for This Dataset:**\n",
    "1. **Random Forest** - Handles interactions well, robust to imbalance\n",
    "2. **XGBoost** - Excellent for tabular data, handles missing values\n",
    "3. **LightGBM** - Fast training, good for large datasets\n",
    "4. **Neural Network** - Can learn complex interactions (requires more tuning)\n",
    "\n",
    "**Class Imbalance Strategies:**\n",
    "* **SMOTE** - Synthetic minority oversampling\n",
    "* **Class weights** - Penalize misclassifying fraud more heavily\n",
    "* **Undersampling** - Reduce majority class (use with caution)\n",
    "* **Ensemble** - Combine multiple approaches\n",
    "\n",
    "**Validation Strategy:**\n",
    "* **Stratified K-Fold** - Maintain fraud rate across folds\n",
    "* **Time-based split** - Not applicable (synthetic data)\n",
    "* **Focus on Precision/Recall** - Not just accuracy due to imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cca622e-2543-4dfb-a7e6-43715ca06ff1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Key insights summary"
    }
   },
   "outputs": [],
   "source": [
    "# Summary of key insights\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY INSIGHTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Overall fraud rate\n",
    "total_txns = df.count()\n",
    "fraud_txns = df.filter(F.col('label') == 'Yes').count()\n",
    "fraud_rate = (fraud_txns / total_txns * 100)\n",
    "\n",
    "print(f\"\\n1. FRAUD OVERVIEW:\")\n",
    "print(f\"   - Total Transactions: {total_txns:,}\")\n",
    "print(f\"   - Fraud Cases: {fraud_txns:,}\")\n",
    "print(f\"   - Fraud Rate: {fraud_rate:.3f}%\")\n",
    "print(f\"   - Class Imbalance: 1:{int(total_txns/fraud_txns)}\")\n",
    "\n",
    "# 2. Amount insights\n",
    "fraud_avg_amount = df.filter(F.col('label') == 'Yes').agg(F.avg('amount')).collect()[0][0]\n",
    "legit_avg_amount = df.filter(F.col('label') == 'No').agg(F.avg('amount')).collect()[0][0]\n",
    "\n",
    "print(f\"\\n2. TRANSACTION AMOUNTS:\")\n",
    "print(f\"   - Average Fraud Amount: ${fraud_avg_amount:.2f}\")\n",
    "print(f\"   - Average Legitimate Amount: ${legit_avg_amount:.2f}\")\n",
    "print(f\"   - Ratio: {fraud_avg_amount/legit_avg_amount:.2f}x higher for fraud\")\n",
    "\n",
    "# 3. Geographic insights\n",
    "print(f\"\\n3. GEOGRAPHIC PATTERNS:\")\n",
    "print(f\"   - Cross-border fraud rate: 4.85% (43x higher than domestic)\")\n",
    "print(f\"   - Italy: 65% fraud rate, 23% of all fraud cases\")\n",
    "print(f\"   - Online: 0.84% fraud rate (53x higher than physical)\")\n",
    "\n",
    "# 4. Temporal insights\n",
    "print(f\"\\n4. TEMPORAL PATTERNS:\")\n",
    "print(f\"   - Online fraud peaks: 10 AM - 1 PM (1.80% fraud rate)\")\n",
    "print(f\"   - Physical fraud peaks: 6 PM - 7 PM (0.13% fraud rate)\")\n",
    "print(f\"   - Year-over-year volatility: Synthetic data with diverse scenarios\")\n",
    "\n",
    "print(f\"\\n5. NEXT STEPS:\")\n",
    "print(f\"   - Review Executive Summary (Cell 3) for high-level findings\")\n",
    "print(f\"   - Check Feature Importance Summary (Section 10) for modeling guidance\")\n",
    "print(f\"   - Use all 10 years of data for training (comprehensive fraud patterns)\")\n",
    "print(f\"   - Focus on Tier 1 features: is_cross_border, location_type, hour_x_type\")\n",
    "print(f\"   - Address class imbalance with SMOTE or class weights\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… EXPLORATORY DATA ANALYSIS COMPLETE!\")\n",
    "print(\"Ready for Model Building\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "fraud_eda_day1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
