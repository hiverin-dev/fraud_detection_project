{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8254884-42e1-4e8e-9c12-29758d3f121c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Fraud Detection - Gold Layer\n",
    "\n",
    "## Purpose\n",
    "Create analytics-ready, denormalized tables by joining silver layer tables for:\n",
    "- Machine learning model training\n",
    "- Business intelligence and reporting\n",
    "- Feature-rich datasets with all relevant dimensions\n",
    "\n",
    "## Gold Tables Created\n",
    "1. `tx_train_gold` - Training dataset (labeled transactions + all dimensions)\n",
    "2. `tx_score_gold` - Scoring dataset (unlabeled transactions + all dimensions)\n",
    "\n",
    "## Data Flow\n",
    "Silver Tables → Join Dimensions → Gold Tables (denormalized, analytics-ready)\n",
    "\n",
    "## Joins Performed\n",
    "- Transactions + Labels (inner join for train, left anti for score)\n",
    "- Transactions + Users (left join on client_id)\n",
    "- Transactions + Cards (left join on card_id)\n",
    "- Transactions + MCC (left join on mcc code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bffc2e1-994f-4377-91ac-f3394d2f2056",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create tx_train_gold"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# Load silver tables\n",
    "tx_train = spark.table(\"workspace.fraud.tx_train_silver\")  # Already has labels joined\n",
    "usr = spark.table(\"workspace.fraud.users_silver\")\n",
    "crd = spark.table(\"workspace.fraud.cards_silver\")\n",
    "mcc = spark.table(\"workspace.fraud.mcc_dim_silver\")\n",
    "\n",
    "# Create denormalized gold table with all dimensions\n",
    "tx_train_gold = (\n",
    "    tx_train\n",
    "      .join(broadcast(usr), tx_train.client_id == usr.id, \"left\")\n",
    "      .drop(usr.id)  # Drop user id to avoid duplicate\n",
    "      .join(broadcast(crd), tx_train.card_id == crd.id, \"left\")\n",
    "      .drop(crd.id, crd.client_id)  # Drop card id and client_id to avoid duplicates\n",
    "      .join(broadcast(mcc), \"mcc\", \"left\")  # Join on mcc code\n",
    ")\n",
    "\n",
    "# Save to gold table\n",
    "tx_train_gold.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").format(\"delta\") \\\n",
    "    .saveAsTable(\"workspace.fraud.tx_train_gold\")\n",
    "\n",
    "print(f\"Created tx_train_gold with {tx_train_gold.count():,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d457bc-dcfa-4eee-826e-ec0ffd6f068d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create tx_score_gold"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# Load silver tables\n",
    "tx_score = spark.table(\"workspace.fraud.tx_score_silver\")  # Unlabeled transactions\n",
    "usr = spark.table(\"workspace.fraud.users_silver\")\n",
    "crd = spark.table(\"workspace.fraud.cards_silver\")\n",
    "mcc = spark.table(\"workspace.fraud.mcc_dim_silver\")\n",
    "\n",
    "# Create denormalized gold table with all dimensions\n",
    "tx_score_gold = (\n",
    "    tx_score\n",
    "      .join(broadcast(usr), tx_score.client_id == usr.id, \"left\")\n",
    "      .drop(usr.id)  # Drop user id to avoid duplicate\n",
    "      .join(broadcast(crd), tx_score.card_id == crd.id, \"left\")\n",
    "      .drop(crd.id, crd.client_id)  # Drop card id and client_id to avoid duplicates\n",
    "      .join(broadcast(mcc), \"mcc\", \"left\")  # Join on mcc code\n",
    ")\n",
    "\n",
    "# Save to gold table\n",
    "tx_score_gold.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").format(\"delta\") \\\n",
    "    .saveAsTable(\"workspace.fraud.tx_score_gold\")\n",
    "\n",
    "print(f\"Created tx_score_gold with {tx_score_gold.count():,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beb640e0-6f04-45dd-bf56-2bec5274b22e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Verification\n",
    "Verify gold tables were created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3d16c86-2b14-40d8-8851-e1dc3d65fcbf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Verify gold tables"
    }
   },
   "outputs": [],
   "source": [
    "# Summary of all gold tables\n",
    "print(\"Gold Layer Tables Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gold_tables = [\n",
    "    \"tx_train_gold\",\n",
    "    \"tx_score_gold\"\n",
    "]\n",
    "\n",
    "for table in gold_tables:\n",
    "    try:\n",
    "        count = spark.sql(f\"SELECT COUNT(*) as cnt FROM workspace.fraud.{table}\").collect()[0]['cnt']\n",
    "        print(f\"{table:25} {count:>15,} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"{table:25} ERROR: {str(e)[:30]}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Show label distribution in training set\n",
    "print(\"Label Distribution in tx_train_gold:\")\n",
    "spark.sql(\"SELECT label, COUNT(*) as count FROM workspace.fraud.tx_train_gold GROUP BY label ORDER BY label\").show()\n",
    "\n",
    "# Show column count\n",
    "print(f\"tx_train_gold has {len(spark.table('workspace.fraud.tx_train_gold').columns)} columns (denormalized)\")\n",
    "print(f\"tx_score_gold has {len(spark.table('workspace.fraud.tx_score_gold').columns)} columns (denormalized)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f644d65-7c5e-4b7d-a195-4adcc42b6181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Geographic Features\n",
    "Verify that geographic categorization features from Silver layer are included in Gold tables:\n",
    "- `location_type`: Categorizes transactions as US_State, International, Online, or Unknown\n",
    "- `is_cross_border`: Boolean flag for international transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e6a3f66-3970-431a-91d0-f2cd8ad1e9f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Geographic Features\n",
    "Verify that geographic categorization features from Silver layer are included in Gold tables:\n",
    "- `location_type`: Categorizes transactions as US_State, International, Online, or Unknown\n",
    "- `is_cross_border`: Boolean flag for international transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bbb1e37-7853-4396-837a-8fe48e96d7ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "print(\"Geographic Features in Gold Tables\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if geographic columns exist\n",
    "train_cols = spark.table('workspace.fraud.tx_train_gold').columns\n",
    "print(f\"\\n✓ location_type in tx_train_gold: {'location_type' in train_cols}\")\n",
    "print(f\"✓ is_cross_border in tx_train_gold: {'is_cross_border' in train_cols}\")\n",
    "\n",
    "# Show distribution in training set\n",
    "print(\"\\n1. Location Type Distribution (Training Set):\")\n",
    "spark.table('workspace.fraud.tx_train_gold') \\\n",
    "    .groupBy('location_type').count() \\\n",
    "    .orderBy(F.desc('count')).show()\n",
    "\n",
    "print(\"\\n2. Cross-Border Transaction Summary (Training Set):\")\n",
    "spark.table('workspace.fraud.tx_train_gold') \\\n",
    "    .groupBy('is_cross_border').count().show()\n",
    "\n",
    "# Fraud rate by location type\n",
    "print(\"\\n3. Fraud Rate by Location Type:\")\n",
    "spark.table('workspace.fraud.tx_train_gold') \\\n",
    "    .groupBy('location_type') \\\n",
    "    .agg(\n",
    "        F.count('*').alias('total_txns'),\n",
    "        F.sum(F.when(F.col('label') == 'Yes', 1).otherwise(0)).alias('fraud_count')\n",
    "    ) \\\n",
    "    .withColumn('fraud_rate_pct', F.round((F.col('fraud_count') / F.col('total_txns') * 100), 2)) \\\n",
    "    .orderBy(F.desc('fraud_rate_pct')).show(truncate=False)\n",
    "\n",
    "print(\"\\n4. Top International Locations (Fraud Cases):\")\n",
    "spark.table('workspace.fraud.tx_train_gold') \\\n",
    "    .filter((F.col('location_type') == 'International') & (F.col('label') == 'Yes')) \\\n",
    "    .groupBy('merchant_state', 'merchant_city') \\\n",
    "    .count() \\\n",
    "    .orderBy(F.desc('count')).show(10, truncate=False)\n",
    "\n",
    "print(\"\\n✅ Geographic features successfully included in Gold layer!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "577053fe-e7ac-4512-b24e-8f6214738f13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show sample records with geographic features\n",
    "print(\"Sample Records with Geographic Features:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "spark.table('workspace.fraud.tx_train_gold') \\\n",
    "    .select(\n",
    "        'tx_id', 'merchant_state', 'merchant_city', \n",
    "        'location_type', 'is_cross_border', 'amount', 'label'\n",
    "    ) \\\n",
    "    .filter(F.col('location_type') == 'International') \\\n",
    "    .show(10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "fraud_gold_build",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
