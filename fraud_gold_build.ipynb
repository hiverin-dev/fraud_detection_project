{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8254884-42e1-4e8e-9c12-29758d3f121c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Fraud Detection - Gold Layer\n",
    "\n",
    "## Purpose\n",
    "Create analytics-ready, denormalized tables by joining silver layer tables for:\n",
    "- Machine learning model training\n",
    "- Business intelligence and reporting\n",
    "- Feature-rich datasets with all relevant dimensions\n",
    "\n",
    "## Gold Tables Created\n",
    "1. `tx_train_gold` - Training dataset (labeled transactions + all dimensions)\n",
    "2. `tx_score_gold` - Scoring dataset (unlabeled transactions + all dimensions)\n",
    "\n",
    "## Data Flow\n",
    "Silver Tables → Join Dimensions → Gold Tables (denormalized, analytics-ready)\n",
    "\n",
    "## Joins Performed\n",
    "- Transactions + Labels (inner join for train, left anti for score)\n",
    "- Transactions + Users (left join on client_id)\n",
    "- Transactions + Cards (left join on card_id)\n",
    "- Transactions + MCC (left join on mcc code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bffc2e1-994f-4377-91ac-f3394d2f2056",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create tx_train_gold"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# Load silver tables\n",
    "tx_train = spark.table(\"workspace.fraud.tx_train_silver\")  # Already has labels joined\n",
    "usr = spark.table(\"workspace.fraud.users_silver\")\n",
    "crd = spark.table(\"workspace.fraud.cards_silver\")\n",
    "mcc = spark.table(\"workspace.fraud.mcc_dim_silver\")\n",
    "\n",
    "# Create denormalized gold table with all dimensions\n",
    "tx_train_gold = (\n",
    "    tx_train\n",
    "      .join(broadcast(usr), tx_train.client_id == usr.id, \"left\")\n",
    "      .drop(usr.id)  # Drop user id to avoid duplicate\n",
    "      .join(broadcast(crd), tx_train.card_id == crd.id, \"left\")\n",
    "      .drop(crd.id, crd.client_id)  # Drop card id and client_id to avoid duplicates\n",
    "      .join(broadcast(mcc), \"mcc\", \"left\")  # Join on mcc code\n",
    ")\n",
    "\n",
    "# Save to gold table\n",
    "tx_train_gold.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").format(\"delta\") \\\n",
    "    .saveAsTable(\"workspace.fraud.tx_train_gold\")\n",
    "\n",
    "print(f\"Created tx_train_gold with {tx_train_gold.count():,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d457bc-dcfa-4eee-826e-ec0ffd6f068d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create tx_score_gold"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# Load silver tables\n",
    "tx_score = spark.table(\"workspace.fraud.tx_score_silver\")  # Unlabeled transactions\n",
    "usr = spark.table(\"workspace.fraud.users_silver\")\n",
    "crd = spark.table(\"workspace.fraud.cards_silver\")\n",
    "mcc = spark.table(\"workspace.fraud.mcc_dim_silver\")\n",
    "\n",
    "# Create denormalized gold table with all dimensions\n",
    "tx_score_gold = (\n",
    "    tx_score\n",
    "      .join(broadcast(usr), tx_score.client_id == usr.id, \"left\")\n",
    "      .drop(usr.id)  # Drop user id to avoid duplicate\n",
    "      .join(broadcast(crd), tx_score.card_id == crd.id, \"left\")\n",
    "      .drop(crd.id, crd.client_id)  # Drop card id and client_id to avoid duplicates\n",
    "      .join(broadcast(mcc), \"mcc\", \"left\")  # Join on mcc code\n",
    ")\n",
    "\n",
    "# Save to gold table\n",
    "tx_score_gold.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").format(\"delta\") \\\n",
    "    .saveAsTable(\"workspace.fraud.tx_score_gold\")\n",
    "\n",
    "print(f\"Created tx_score_gold with {tx_score_gold.count():,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beb640e0-6f04-45dd-bf56-2bec5274b22e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## Verification\n",
    "Verify gold tables were created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3d16c86-2b14-40d8-8851-e1dc3d65fcbf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Verify gold tables"
    }
   },
   "outputs": [],
   "source": [
    "# Summary of all gold tables\n",
    "print(\"Gold Layer Tables Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gold_tables = [\n",
    "    \"tx_train_gold\",\n",
    "    \"tx_score_gold\"\n",
    "]\n",
    "\n",
    "for table in gold_tables:\n",
    "    try:\n",
    "        count = spark.sql(f\"SELECT COUNT(*) as cnt FROM workspace.fraud.{table}\").collect()[0]['cnt']\n",
    "        print(f\"{table:25} {count:>15,} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"{table:25} ERROR: {str(e)[:30]}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Show label distribution in training set\n",
    "print(\"Label Distribution in tx_train_gold:\")\n",
    "spark.sql(\"SELECT label, COUNT(*) as count FROM workspace.fraud.tx_train_gold GROUP BY label ORDER BY label\").show()\n",
    "\n",
    "# Show column count\n",
    "print(f\"tx_train_gold has {len(spark.table('workspace.fraud.tx_train_gold').columns)} columns (denormalized)\")\n",
    "print(f\"tx_score_gold has {len(spark.table('workspace.fraud.tx_score_gold').columns)} columns (denormalized)\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "fraud_gold_build",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
